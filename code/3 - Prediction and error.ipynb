{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Advanced Learning for Text and Graph Data </h1>\n",
    "<b> Universit√© Paris-Saclay - Master M2 Data Science - February/March 2017</b> <br>\n",
    "<i> Students : Peter Martigny & Mehdi Miah </i> <br>\n",
    "\n",
    "# Third part  : predict and measure the error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#our own modules\n",
    "from map_tools import * #functions computing mean average precision\n",
    "from handy_structures import *\n",
    "\n",
    "#common libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#for words analysis\n",
    "import nltk\n",
    "import string\n",
    "import os\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+') #to remove punctuations\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stem_tokens(tokens):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens)\n",
    "    return stems\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#path to data and intermediate results\n",
    "path_to_data = \"..\\\\data\\\\\"\n",
    "path_to_results = \"..\\\\results\\\\\"\n",
    "\n",
    "## == open files ====\n",
    "\n",
    "#original data\n",
    "training_set = pd.read_csv(path_to_data + 'training_set.csv')\n",
    "training_info = pd.read_csv(path_to_data + 'training_info.csv', \n",
    "                            dtype = {'mid': object, 'date': object, 'body': object, 'recipients' : object})\n",
    "test_set = pd.read_csv(path_to_data + 'test_set.csv')\n",
    "test_info = pd.read_csv(path_to_data + 'test_info.csv',\n",
    "                        dtype = {'mid': object, 'date': object, 'body': object, 'recipients' : object})\n",
    "\n",
    "#intermediate data\n",
    "training_df = pd.read_csv(path_to_results + 'training_df.csv',\n",
    "                          dtype = {'mid': object, 'sender': object, 'date': object, 'body': object, 'recipients' : object})\n",
    "test_df = pd.read_csv(path_to_results + 'test_df.csv',\n",
    "                          dtype = {'mid': object, 'sender': object, 'date': object, 'body': object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>mids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>158713 158697 200301 158679 278595 298162 2002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amr.ibrahim@enron.com</td>\n",
       "      <td>215241 3437 215640 3506 191790 3517 3520 3562 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andrea.ring@enron.com</td>\n",
       "      <td>270705 270706 270707 270708 270709 270710 2707...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sylvia.hu@enron.com</td>\n",
       "      <td>111444 111422 183084 111412 111347 110883 1105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phillip.platter@enron.com</td>\n",
       "      <td>327074 327384 327385 264443 274124 274125 2741...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sender  \\\n",
       "0    karen.buckley@enron.com   \n",
       "1      amr.ibrahim@enron.com   \n",
       "2      andrea.ring@enron.com   \n",
       "3        sylvia.hu@enron.com   \n",
       "4  phillip.platter@enron.com   \n",
       "\n",
       "                                                mids  \n",
       "0  158713 158697 200301 158679 278595 298162 2002...  \n",
       "1  215241 3437 215640 3506 191790 3517 3520 3562 ...  \n",
       "2  270705 270706 270707 270708 270709 270710 2707...  \n",
       "3  111444 111422 183084 111412 111347 110883 1105...  \n",
       "4  327074 327384 327385 264443 274124 274125 2741...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>2000-07-25 08:14:00</td>\n",
       "      <td>Legal has been assessing the risks of doing bl...</td>\n",
       "      <td>robert.badeer@enron.com murray.o neil@enron.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>2000-08-03 02:56:00</td>\n",
       "      <td>Attached is a spreadsheet to estimate export f...</td>\n",
       "      <td>kim.ward@enron.com robert.badeer@enron.com mur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>2000-08-15 05:37:00</td>\n",
       "      <td>Kevin/Bob: Here is a quick rundown on the cons...</td>\n",
       "      <td>robert.badeer@enron.com john.massey@enron.com ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>2000-08-20 14:12:00</td>\n",
       "      <td>check this out and let everyone know what s up...</td>\n",
       "      <td>robert.badeer@enron.com jeff.richter@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>2000-08-22 08:17:00</td>\n",
       "      <td>Further to your letter to us (addressed to Mr....</td>\n",
       "      <td>pgillman@schiffhardin.com kamarlantes@calpx.co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mid                 date                                               body  \\\n",
       "0  60  2000-07-25 08:14:00  Legal has been assessing the risks of doing bl...   \n",
       "1  66  2000-08-03 02:56:00  Attached is a spreadsheet to estimate export f...   \n",
       "2  74  2000-08-15 05:37:00  Kevin/Bob: Here is a quick rundown on the cons...   \n",
       "3  80  2000-08-20 14:12:00  check this out and let everyone know what s up...   \n",
       "4  83  2000-08-22 08:17:00  Further to your letter to us (addressed to Mr....   \n",
       "\n",
       "                                          recipients  \n",
       "0  robert.badeer@enron.com murray.o neil@enron.co...  \n",
       "1  kim.ward@enron.com robert.badeer@enron.com mur...  \n",
       "2  robert.badeer@enron.com john.massey@enron.com ...  \n",
       "3     robert.badeer@enron.com jeff.richter@enron.com  \n",
       "4  pgillman@schiffhardin.com kamarlantes@calpx.co...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>mids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>298389 332383 298390 284071 366982 81773 81791...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amr.ibrahim@enron.com</td>\n",
       "      <td>48260 48465 50344 48268 50330 48237 189979 189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andrea.ring@enron.com</td>\n",
       "      <td>366364 271168 271172 271167 271189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sylvia.hu@enron.com</td>\n",
       "      <td>134931 134856 233549 233517 134895 233584 3736...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phillip.platter@enron.com</td>\n",
       "      <td>274220 274225 274215 274223 274214 274207 2742...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sender  \\\n",
       "0    karen.buckley@enron.com   \n",
       "1      amr.ibrahim@enron.com   \n",
       "2      andrea.ring@enron.com   \n",
       "3        sylvia.hu@enron.com   \n",
       "4  phillip.platter@enron.com   \n",
       "\n",
       "                                                mids  \n",
       "0  298389 332383 298390 284071 366982 81773 81791...  \n",
       "1  48260 48465 50344 48268 50330 48237 189979 189...  \n",
       "2                 366364 271168 271172 271167 271189  \n",
       "3  134931 134856 233549 233517 134895 233584 3736...  \n",
       "4  274220 274225 274215 274223 274214 274207 2742...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1577</td>\n",
       "      <td>2001-11-19 06:59:51</td>\n",
       "      <td>Note:  Stocks of heating oil are very high for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1750</td>\n",
       "      <td>2002-03-05 08:46:57</td>\n",
       "      <td>Kevin Hyatt and I are going for \"sghetti\" at S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1916</td>\n",
       "      <td>2002-02-13 14:17:39</td>\n",
       "      <td>This was forwarded to me and it is funny. - Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2094</td>\n",
       "      <td>2002-01-22 11:33:56</td>\n",
       "      <td>I will be in to and happy to assist too.  I ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2205</td>\n",
       "      <td>2002-01-11 07:12:19</td>\n",
       "      <td>Thanks. I needed a morning chuckle.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mid                 date  \\\n",
       "0  1577  2001-11-19 06:59:51   \n",
       "1  1750  2002-03-05 08:46:57   \n",
       "2  1916  2002-02-13 14:17:39   \n",
       "3  2094  2002-01-22 11:33:56   \n",
       "4  2205  2002-01-11 07:12:19   \n",
       "\n",
       "                                                body  \n",
       "0  Note:  Stocks of heating oil are very high for...  \n",
       "1  Kevin Hyatt and I are going for \"sghetti\" at S...  \n",
       "2  This was forwarded to me and it is funny. - Wi...  \n",
       "3  I will be in to and happy to assist too.  I ma...  \n",
       "4                Thanks. I needed a morning chuckle.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>sender</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47361</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-08-26 22:16:36</td>\n",
       "      <td>The following reports have been waiting for yo...</td>\n",
       "      <td>kimberly.watson@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47362</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-08-27 22:21:02</td>\n",
       "      <td>The following reports have been waiting for yo...</td>\n",
       "      <td>kimberly.watson@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47363</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-08-28 22:25:35</td>\n",
       "      <td>The following reports have been waiting for yo...</td>\n",
       "      <td>kimberly.watson@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45909</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-09-13 22:24:08</td>\n",
       "      <td>Employee Name: Kimberly WatsonReport Name:   E...</td>\n",
       "      <td>kimberly.watson@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82030</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-09-17 09:24:00</td>\n",
       "      <td>The following expense report is ready for appr...</td>\n",
       "      <td>barry.tycholiz@enron.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mid                             sender                 date  \\\n",
       "0  47361  enron_update@concureworkplace.com  0001-08-26 22:16:36   \n",
       "1  47362  enron_update@concureworkplace.com  0001-08-27 22:21:02   \n",
       "2  47363  enron_update@concureworkplace.com  0001-08-28 22:25:35   \n",
       "3  45909  enron_update@concureworkplace.com  0001-09-13 22:24:08   \n",
       "4  82030  enron_update@concureworkplace.com  0001-09-17 09:24:00   \n",
       "\n",
       "                                                body  \\\n",
       "0  The following reports have been waiting for yo...   \n",
       "1  The following reports have been waiting for yo...   \n",
       "2  The following reports have been waiting for yo...   \n",
       "3  Employee Name: Kimberly WatsonReport Name:   E...   \n",
       "4  The following expense report is ready for appr...   \n",
       "\n",
       "                  recipients  \n",
       "0  kimberly.watson@enron.com  \n",
       "1  kimberly.watson@enron.com  \n",
       "2  kimberly.watson@enron.com  \n",
       "3  kimberly.watson@enron.com  \n",
       "4   barry.tycholiz@enron.com  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>sender</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284098</td>\n",
       "      <td>jonathan.mckay@enron.com</td>\n",
       "      <td>2001-11-02 05:25:29</td>\n",
       "      <td>How is everyone.....mother, child.........fath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272008</td>\n",
       "      <td>dutch.quigley@enron.com</td>\n",
       "      <td>2001-11-02 05:34:55</td>\n",
       "      <td>-----Original Message-----From: \\tWesner-Soon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49273</td>\n",
       "      <td>james.d.steffes@enron.com</td>\n",
       "      <td>2001-11-02 05:57:55</td>\n",
       "      <td>Janine -Ok for you to cover the whole country....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71901</td>\n",
       "      <td>kim.ward@enron.com</td>\n",
       "      <td>2001-11-02 06:10:47</td>\n",
       "      <td>when?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82354</td>\n",
       "      <td>barry.tycholiz@enron.com</td>\n",
       "      <td>2001-11-02 06:17:44</td>\n",
       "      <td>WOW.... I am positive that your beautiful wife...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mid                     sender                 date  \\\n",
       "0  284098   jonathan.mckay@enron.com  2001-11-02 05:25:29   \n",
       "1  272008    dutch.quigley@enron.com  2001-11-02 05:34:55   \n",
       "2   49273  james.d.steffes@enron.com  2001-11-02 05:57:55   \n",
       "3   71901         kim.ward@enron.com  2001-11-02 06:10:47   \n",
       "4   82354   barry.tycholiz@enron.com  2001-11-02 06:17:44   \n",
       "\n",
       "                                                body  \n",
       "0  How is everyone.....mother, child.........fath...  \n",
       "1   -----Original Message-----From: \\tWesner-Soon...  \n",
       "2  Janine -Ok for you to cover the whole country....  \n",
       "3                                              when?  \n",
       "4  WOW.... I am positive that your beautiful wife...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First way : temporal on all emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False :\n",
    "    #Temporal separation between training and test\n",
    "    # already time ordered\n",
    "    pct_train = 0.8\n",
    "    idx_separation = round(pct_train * training_info.shape[0])\n",
    "    mid_train = training_info['mid'][:idx_separation]\n",
    "    mid_test = training_info['mid'][idx_separation:]\n",
    "\n",
    "    # Separation in training_info\n",
    "    training_info_train = training_info[:idx_separation]\n",
    "    training_info_test = training_info[idx_separation:]\n",
    "\n",
    "    #Separation in training_set\n",
    "    training_set_train = training_set.copy()\n",
    "    training_set_test = training_set.copy()\n",
    "\n",
    "    for row in range(training_set_train.shape[0]):\n",
    "        mids = training_set_train['mids'][row].split(' ')\n",
    "        new_mid = list(set(mids) & set(mid_train))\n",
    "        training_set_train['mids'][row] = ' '.join(new_mid)\n",
    "\n",
    "    for row in range(training_set_test.shape[0]):\n",
    "        mids = training_set_test['mids'][row].split(' ')\n",
    "        new_mid = list(set(mids) & set(mid_test))\n",
    "        training_set_test['mids'][row] = ' '.join(new_mid)  \n",
    "        \n",
    "    #dataframe\n",
    "    training_df_train = transform_dataset(training_info_train, training_set_train)\n",
    "    training_df_test = transform_dataset(training_info_test, training_set_test)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some users are in the test set and NOT in the train set : mike.carson@enron.com, vkaminski@aol.com and christina.valdez@enron.com !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second way : pure randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    training_all_senders = training_set['sender'].get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if True : \n",
    "    # Separation in training_df\n",
    "    training_df_train, training_df_test = train_test_split(training_df, test_size=0.2, random_state=0)\n",
    "\n",
    "    training_df_train = training_df_train.reset_index(drop=True)\n",
    "    training_df_test = training_df_test.reset_index(drop=True)\n",
    "\n",
    "    mid_train = training_df_train['mid']\n",
    "    mid_test = training_df_test['mid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    # Construction of _set with for each sender, the list of emails\n",
    "\n",
    "    #Training\n",
    "    training_set_train = pd.DataFrame()\n",
    "    for sender in tqdm(training_all_senders):\n",
    "        mids = training_df_train[training_df_train['sender'] == sender]['mid'].values.tolist()\n",
    "        mids = ' '.join(list(map(str, mids)))\n",
    "        training_set_train_sender = pd.DataFrame({'sender':[sender], 'mids': [mids]})\n",
    "\n",
    "        training_set_train = training_set_train.append(training_set_train_sender)\n",
    "\n",
    "    #reorder the columns\n",
    "    training_set_train = training_set_train.reindex_axis(['sender', 'mids'], axis = 1)\n",
    "\n",
    "    #add clean index\n",
    "    training_set_train = training_set_train.reset_index(drop=True)\n",
    "\n",
    "    #Test\n",
    "    training_set_test = pd.DataFrame()\n",
    "    for sender in tqdm(training_all_senders):\n",
    "        mids = training_df_test[training_df_test['sender'] == sender]['mid'].values.tolist()\n",
    "        mids = ' '.join(list(map(str, mids)))\n",
    "        training_set_test_sender = pd.DataFrame({'sender':[sender], 'mids': [mids]})\n",
    "\n",
    "        training_set_test = training_set_test.append(training_set_test_sender)\n",
    "\n",
    "    #reorder the columns\n",
    "    training_set_test = training_set_test.reindex_axis(['sender', 'mids'], axis = 1)\n",
    "\n",
    "    #add clean index\n",
    "    training_set_test = training_set_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    # Construction of _info with info about each mail\n",
    "\n",
    "    #Training\n",
    "    mids_train = training_df_train.mid.get_values().astype('str')\n",
    "    training_info_train = training_info[(training_info['mid']).isin(mids_train)]\n",
    "\n",
    "    #Test\n",
    "    mids_test = training_df_test.mid.get_values().astype('str')\n",
    "    training_info_test = training_info[(training_info['mid']).isin(mids_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### third way : temporal by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    training_all_senders = training_set['sender'].get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    def split_data_v3(training_df, training_all_senders, pct_train = 0.8):\n",
    "        #Initialisation of the two dataframe for learning and testing\n",
    "        training_df_train = pd.DataFrame()\n",
    "        training_df_test = pd.DataFrame()\n",
    "\n",
    "        #We fill the values by taking the oldest emails in the train and the newest in test dataframe\n",
    "        for sender in tqdm(training_all_senders):\n",
    "            #dataframe with all emails sent by the sender\n",
    "            training_df_sender = training_df[training_df['sender'] == sender] #non void\n",
    "            limit = round(pct_train * training_df_sender.shape[0])\n",
    "\n",
    "            training_df_train_sender = training_df_sender[:limit]\n",
    "            training_df_test_sender = training_df_sender[limit:]\n",
    "\n",
    "            training_df_train = training_df_train.append(training_df_train_sender)\n",
    "            training_df_test = training_df_test.append(training_df_test_sender)\n",
    "\n",
    "        #put the right index\n",
    "        training_df_train = training_df_train.reset_index(drop=True)\n",
    "        training_df_test = training_df_test.reset_index(drop=True)\n",
    "\n",
    "        return training_df_train, training_df_test\n",
    "\n",
    "    training_df_train, training_df_test = split_data_v3(training_df, training_all_senders, pct_train = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Construction of _set with for each sender, the list of emails\n",
    "\n",
    "    #Training\n",
    "    training_set_train = pd.DataFrame()\n",
    "    for sender in tqdm(training_all_senders):\n",
    "        mids = training_df_train[training_df_train['sender'] == sender]['mid'].values.tolist()\n",
    "        mids = ' '.join(list(map(str, mids)))\n",
    "        training_set_train_sender = pd.DataFrame({'sender':[sender], 'mids': [mids]})\n",
    "\n",
    "        training_set_train = training_set_train.append(training_set_train_sender)\n",
    "\n",
    "    #reorder the columns\n",
    "    training_set_train = training_set_train.reindex_axis(['sender', 'mids'], axis = 1)\n",
    "\n",
    "    #add clean index\n",
    "    training_set_train = training_set_train.reset_index(drop=True)\n",
    "\n",
    "    #Test\n",
    "    training_set_test = pd.DataFrame()\n",
    "    for sender in tqdm(training_all_senders):\n",
    "        mids = training_df_test[training_df_test['sender'] == sender]['mid'].values.tolist()\n",
    "        mids = ' '.join(list(map(str, mids)))\n",
    "        training_set_test_sender = pd.DataFrame({'sender':[sender], 'mids': [mids]})\n",
    "\n",
    "        training_set_test = training_set_test.append(training_set_test_sender)\n",
    "\n",
    "    #reorder the columns\n",
    "    training_set_test = training_set_test.reindex_axis(['sender', 'mids'], axis = 1)\n",
    "\n",
    "    #add clean index\n",
    "    training_set_test = training_set_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Construction of _info with info about each mail\n",
    "\n",
    "    #Training\n",
    "    mids_train = training_df_train.mid.get_values().astype('str')\n",
    "    training_info_train = training_info[(training_info['mid']).isin(mids_train)]\n",
    "\n",
    "    #Test\n",
    "    mids_test = training_df_test.mid.get_values().astype('str')\n",
    "    training_info_test = training_info[(training_info['mid']).isin(mids_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check on cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some sanity test : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SANITY CHECK ON training\n",
      "Number of emails in the full dataframe : 43613 \t _info : 43613 \t _set : 43613 \n",
      "\n",
      "SANITY CHECK ON training for train\n",
      "Number of emails in the full dataframe : 34890 \t _info : 34890 \t _set : 34890 \n",
      "\n",
      "SANITY CHECK ON training for test\n",
      "Number of emails in the full dataframe : 8723 \t _info : 8723 \t _set : 8723 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## == Check on the number of email in each part ====\n",
    "n_senders = 125\n",
    "\n",
    "def sanity_check_n_emails(dataset_df, dataset_info, dataset_set, name):\n",
    "    n_mails_dataset_df = dataset_df.shape[0]\n",
    "    n_mails_dataset_info = dataset_info.shape[0]\n",
    "    n_mails_dataset_set = np.sum([len(dataset_set.mids[i].split(' ')) for i in range(n_senders)])\n",
    "    print('SANITY CHECK ON ' + name)\n",
    "    print('Number of emails in the full dataframe : %.0f \\t _info : %.0f \\t _set : %.0f \\n' \n",
    "          %(n_mails_dataset_df, n_mails_dataset_info, n_mails_dataset_set))\n",
    "\n",
    "#In the training (train + test)\n",
    "sanity_check_n_emails(training_df, training_info, training_set, \"training\")\n",
    "\n",
    "#In the train\n",
    "sanity_check_n_emails(training_df_train, training_info_train ,training_set_train , \"training for train\")\n",
    "\n",
    "#In the test\n",
    "sanity_check_n_emails(training_df_test, training_info_test ,training_set_test, \"training for test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some handy structures on the train of cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    }
   ],
   "source": [
    "# Construct the address book for each sender, take 2/3 minutes\n",
    "address_books_train = get_address_books(training_info_train, training_set_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save all unique sender names\n",
    "emails_ids_per_sender_train = get_mids_per_sender(training_set_train)\n",
    "all_senders_train = emails_ids_per_sender_train.keys()\n",
    "\n",
    "# save all unique recipient names    \n",
    "all_recs_train = list(set([elt[0] for sublist in address_books_train.values() for elt in sublist]))\n",
    "\n",
    "# save all unique user names \n",
    "all_users_train = []\n",
    "all_users_train.extend(all_senders_train)\n",
    "all_users_train.extend(all_recs_train)\n",
    "all_users_train = list(set(all_users_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['190543', '190623', '42575', '40843', '190737']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#An example\n",
    "emails_ids_per_sender_train['enron_update@concureworkplace.com'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_mids_sender_to_recipient(address_books, dataset_df):\n",
    "    '''\n",
    "    Computes the list of mids for each couple (sender, recipient)\n",
    "    '''\n",
    "    #a new dictionnary\n",
    "    mids_sender_to_recipient = {}\n",
    "    \n",
    "    #all the senders\n",
    "    all_senders = address_books_train.keys()\n",
    "    \n",
    "    for sender in tqdm(all_senders):\n",
    "        #the mails sent by the sender\n",
    "        mask_sender = (sender == dataset_df.sender)\n",
    "        sub_dataset_df = dataset_df[mask_sender]\n",
    "        sub_dataset_df = sub_dataset_df.reset_index(drop=True)\n",
    "        \n",
    "        rec_out = address_books[sender]\n",
    "        for rec, out in rec_out: \n",
    "\n",
    "            #we search amongst them, those sent to the recipient\n",
    "            mask_recipient = [rec in sub_dataset_df.recipients[i] for i in range(sub_dataset_df.shape[0])]\n",
    "\n",
    "            #we save the result\n",
    "            mids_sender_to_recipient[(sender, rec)] = sub_dataset_df['mid'][mask_recipient].values.tolist()\n",
    "        \n",
    "    return mids_sender_to_recipient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    }
   ],
   "source": [
    "# Takes 2/3 minutes\n",
    "mids_sender_to_recipient = get_mids_sender_to_recipient(address_books_train, training_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['28043', '27895', '27898', '27985', '28076']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#An example\n",
    "mids_sender_to_recipient['enron_update@concureworkplace.com', 'mark.whitt@enron.com'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Mids of mails received by each senders\n",
    "def get_mids_received_by_user(dataset_df):\n",
    "    emails_ids_per_sender = {} \n",
    "\n",
    "    #iterate on each mail\n",
    "    for row in tqdm(range(dataset_df.shape[0])):\n",
    "        mid = dataset_df['mid'][row]\n",
    "        recipients = dataset_df['recipients'][row].split(' ')\n",
    "\n",
    "        for rec in recipients:\n",
    "            if rec in emails_ids_per_sender.keys():\n",
    "                emails_ids_per_sender[rec] = emails_ids_per_sender[rec] + [mid]\n",
    "            else:\n",
    "                emails_ids_per_sender[rec] = [mid]\n",
    "                \n",
    "    return emails_ids_per_sender            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    }
   ],
   "source": [
    "#Mails received by user\n",
    "mids_received_by_user_train = get_mids_received_by_user(training_df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pr√©diction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random predictions on all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HERE THE PREDICTION WILL ONLY DEPENDS ON THE SENDER !\n",
    "def predictions_random_per_sender(dataset_set, all_users, k=10):\n",
    "\n",
    "    # will contain email ids, predictions for random baseline\n",
    "    predictions_random_per_sender = {}\n",
    "\n",
    "    for index, row in dataset_set.iterrows():\n",
    "        name_ids = row.tolist() #sender + all ones mails)\n",
    "        sender = name_ids[0]\n",
    "\n",
    "        predictions_random_per_sender[sender] = random.sample(all_users, k)\n",
    "        \n",
    "    return predictions_random_per_sender    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make some predictions\n",
    "predictions_random = predictions_random_per_sender(training_set_train, all_users_train)\n",
    "\n",
    "#Fill the dataframe\n",
    "training_df_test['random_pred'] = None\n",
    "for row in range(training_df_test.shape[0]): #for each mail\n",
    "    sender = training_df_test['sender'][row]\n",
    "\n",
    "    #random prediction\n",
    "    training_df_test['random_pred'][row] = predictions_random[sender] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>sender</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipients</th>\n",
       "      <th>random_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337773</td>\n",
       "      <td>chris.germany@enron.com</td>\n",
       "      <td>2000-03-08 10:05:00</td>\n",
       "      <td>Looks good.Stephanie Sever   03/08/2000 05:35 ...</td>\n",
       "      <td>stephanie.sever@enron.com</td>\n",
       "      <td>[javier.li@enron.com, downes.andrew@enron.com,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112428</td>\n",
       "      <td>susan.scott@enron.com</td>\n",
       "      <td>2001-05-04 12:02:26</td>\n",
       "      <td>oh, it s on!</td>\n",
       "      <td>adriane.schultea@enron.com misti.day@enron.com...</td>\n",
       "      <td>[dutch.quigley@enron.com, rick.suttle@enron.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>362746</td>\n",
       "      <td>chris.dorland@enron.com</td>\n",
       "      <td>2000-11-13 03:25:00</td>\n",
       "      <td>George has Oyster Creek coming back Nov. 25. W...</td>\n",
       "      <td>ricardo.perez@enron.com</td>\n",
       "      <td>[philip.conn@enron.com, carlos.choudri@csfb.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333249</td>\n",
       "      <td>c..giron@enron.com</td>\n",
       "      <td>2000-07-24 03:17:00</td>\n",
       "      <td>Last Friday I was trying to get into my accoun...</td>\n",
       "      <td>onepass@coair.com</td>\n",
       "      <td>[roncarroll@bracepatt.com, kimberly.rizzi@enro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>384123</td>\n",
       "      <td>eric.bass@enron.com</td>\n",
       "      <td>2000-08-17 06:53:00</td>\n",
       "      <td>I want to trade you a 4th, 6th and 8th round p...</td>\n",
       "      <td>lqcolombo@aol.com</td>\n",
       "      <td>[david.frost@enron.com, tomas.szamosvolgyi@enr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mid                   sender                 date  \\\n",
       "0  337773  chris.germany@enron.com  2000-03-08 10:05:00   \n",
       "1  112428    susan.scott@enron.com  2001-05-04 12:02:26   \n",
       "2  362746  chris.dorland@enron.com  2000-11-13 03:25:00   \n",
       "3  333249       c..giron@enron.com  2000-07-24 03:17:00   \n",
       "4  384123      eric.bass@enron.com  2000-08-17 06:53:00   \n",
       "\n",
       "                                                body  \\\n",
       "0  Looks good.Stephanie Sever   03/08/2000 05:35 ...   \n",
       "1                                      oh, it s on!    \n",
       "2  George has Oyster Creek coming back Nov. 25. W...   \n",
       "3  Last Friday I was trying to get into my accoun...   \n",
       "4  I want to trade you a 4th, 6th and 8th round p...   \n",
       "\n",
       "                                          recipients  \\\n",
       "0                          stephanie.sever@enron.com   \n",
       "1  adriane.schultea@enron.com misti.day@enron.com...   \n",
       "2                            ricardo.perez@enron.com   \n",
       "3                                  onepass@coair.com   \n",
       "4                                  lqcolombo@aol.com   \n",
       "\n",
       "                                         random_pred  \n",
       "0  [javier.li@enron.com, downes.andrew@enron.com,...  \n",
       "1  [dutch.quigley@enron.com, rick.suttle@enron.co...  \n",
       "2  [philip.conn@enron.com, carlos.choudri@csfb.co...  \n",
       "3  [roncarroll@bracepatt.com, kimberly.rizzi@enro...  \n",
       "4  [david.frost@enron.com, tomas.szamosvolgyi@enr...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random predictions on the address book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HERE THE PREDICTION WILL ONLY DEPENDS ON THE SENDER !\n",
    "\n",
    "def predictions_random_address_book_per_sender(dataset_set, address_books, k=10):\n",
    "    '''\n",
    "    Recommends recipients randomly amongst the addresss books of the sender\n",
    "    The number of recipients may be under k if the sender has not sent enough emails.\n",
    "    '''\n",
    "    # will contain email ids, predictions for random baseline\n",
    "    predictions_random_address_book_per_sender = {}\n",
    "    for index, row in dataset_set.iterrows():\n",
    "        name_ids = row.tolist() #sender + all ones mails)\n",
    "        sender = name_ids[0]\n",
    "\n",
    "        recipients_of_the_sender = [elt[0] for elt in address_books[sender]]\n",
    "        n_recipients_of_the_sender = len(recipients_of_the_sender)\n",
    "        \n",
    "        predictions_random_address_book_per_sender[sender] = random.sample(recipients_of_the_sender, min(k,n_recipients_of_the_sender))\n",
    "    return predictions_random_address_book_per_sender    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make some predictions\n",
    "predictions_random_address_book = predictions_random_address_book_per_sender(training_set_train, address_books_train)\n",
    "\n",
    "#Fill the dataframe\n",
    "training_df_test['random_pred_address_book'] = None\n",
    "for row in range(training_df_test.shape[0]): #for each mail\n",
    "    sender = training_df_test['sender'][row]\n",
    "\n",
    "    #random prediction\n",
    "    training_df_test['random_pred_address_book'][row] = predictions_random_address_book[sender]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency based predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HERE THE PREDICTION WILL ONLY DEPENDS ON THE SENDER !\n",
    "def predictions_frequency_per_sender(dataset_set, address_books, k = 10):\n",
    "\n",
    "    # will contain email ids, predictions for frequency baseline\n",
    "    predictions_frequency_per_sender = {}\n",
    "\n",
    "    for index, row in dataset_set.iterrows():\n",
    "        name_ids = row.tolist() #sender + all ones mails\n",
    "        sender = name_ids[0]\n",
    "\n",
    "        # select k most frequent recipients for the user\n",
    "        predictions_frequency_per_sender[sender] = [elt[0] for elt in address_books[sender][:k]]\n",
    "        \n",
    "    return predictions_frequency_per_sender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make some predictions\n",
    "predictions_frequency = predictions_frequency_per_sender(training_set_train, address_books_train)\n",
    "\n",
    "#Fill the dataframe\n",
    "training_df_test['freq_pred'] = None\n",
    "for row in range(training_df_test.shape[0]): #for each mail\n",
    "    sender = training_df_test['sender'][row]\n",
    "\n",
    "    #random prediction\n",
    "    training_df_test['freq_pred'][row] = predictions_frequency[sender]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted frequency-based predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weighted_score(dataset_df):\n",
    "    '''\n",
    "    Computes a score between the sender and the recipient\n",
    "    score(sender, recipient) = sum_{emails from sender to recipients} 1/(number of recipients in the email)\n",
    "    \n",
    "    == Input ==\n",
    "    a dataframe with all the data\n",
    "    == Output ==\n",
    "    a dictionnary where the key is the sender and the value the tuple (recipient, score)\n",
    "    '''\n",
    "    #Learning phase\n",
    "    dict_weight = {} #the key is (sender, recipient)\n",
    "    for row in tqdm(range(dataset_df.shape[0])):\n",
    "\n",
    "        sender = dataset_df['sender'][row]\n",
    "        recipients = dataset_df['recipients'][row].split(' ')\n",
    "        n_recipients = len(recipients)\n",
    "\n",
    "        for rec in recipients: #for each recipients\n",
    "            key = sender, rec\n",
    "            if key in dict_weight : \n",
    "                dict_weight[key] =  dict_weight[key] + 1./n_recipients\n",
    "            else:\n",
    "                dict_weight[key] = 1./n_recipients\n",
    "\n",
    "    #The right order\n",
    "    weight_sender_recipient = {} #the key is (sender)\n",
    "    for key, value in dict_weight.items():\n",
    "        sender = key[0]\n",
    "        rec = key[1]\n",
    "\n",
    "        if sender in weight_sender_recipient:\n",
    "            weight_sender_recipient[sender] = sorted(weight_sender_recipient[sender] + [(rec,value)], key=operator.itemgetter(1), reverse = True)      \n",
    "        else:\n",
    "            weight_sender_recipient[sender] = [(rec,value)]\n",
    "            \n",
    "    return dict_weight, weight_sender_recipient      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    }
   ],
   "source": [
    "dict_weight, weight_sender_recipient = get_weighted_score(training_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make some predictions\n",
    "training_df_test['weighted_freq_pred'] = None\n",
    "k=10\n",
    "\n",
    "#Testing phase\n",
    "for row in range(training_df_test.shape[0]): #for each mail\n",
    "    sender = training_df_test['sender'][row]\n",
    "\n",
    "    #random prediction\n",
    "    training_df_test['weighted_freq_pred'][row] = [elt[0] for elt in weight_sender_recipient[sender][:k]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looks for a name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_recipients_from_name(name, all_users):\n",
    "    '''\n",
    "    Gives 0 or 1 recipient email address whose name is the one given is the input\n",
    "    \n",
    "    == Input ==\n",
    "    name : a string with the name one is looking for\n",
    "    all_users : a list of names, where the name is looked for, ordered by preference / score\n",
    "    == Output ==\n",
    "    if name is found, an email address\n",
    "    '''\n",
    "    \n",
    "    if((len(name) > 3)): #remove 'it'\n",
    "        for rec in all_users : \n",
    "            rec_name = rec.split('@')[0] #the part before the @\n",
    "            score = str.find(rec_name, name.lower()) #returns -1 if the name is not in the email address, otherwise its position\n",
    "            if score > -1: #a corresponding email address has been found\n",
    "                return [rec]\n",
    "        return [] #no corresponding email address\n",
    "    return [] #the given name is too short "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mark.mcclure@enron.com']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recipients_from_name('Mark', all_users_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    }
   ],
   "source": [
    "#Make some predictions\n",
    "training_df_test['name_freq_pred'] = None\n",
    "k=10\n",
    "\n",
    "#Testing phase\n",
    "for row in tqdm(range(training_df_test.shape[0])): #for each mail\n",
    "    sender = training_df_test['sender'][row]\n",
    "    name_rec = training_df_test['body'][row].split(' ')[:1][0]\n",
    "\n",
    "    #remove some nasty character\n",
    "    #name_rec = str(name_rec).replace(',', '') \n",
    "    \n",
    "    #find the possible recipients from this first word, amongst those the sender has already sent an email\n",
    "    address_book_sender = [elt[0] for elt in address_books_train[sender]] #ordered by the frequency ! \n",
    "    \n",
    "    recipients_from_name = get_recipients_from_name(name_rec, address_book_sender)\n",
    "\n",
    "    #add the frequent recipients\n",
    "    recipients_from_frequency = predictions_frequency[sender]\n",
    "    \n",
    "    #cumul\n",
    "    result = recipients_from_name\n",
    "    result.extend(x for x in recipients_from_frequency if x not in result)\n",
    "\n",
    "    training_df_test['name_freq_pred'][row] = result[:k]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                 | 0/8723 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chris.germany@enron.com\n",
      "1968\n",
      "1968\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mehdi\\Annexes\\PythonENSAE_v2\\python\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py:318: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n",
      "  out = N.ndarray.__getitem__(self, index)\n"
     ]
    }
   ],
   "source": [
    "# TOO LONG\n",
    "\n",
    "#early optimization is the root of all evil\n",
    "k=10\n",
    "#Make some predictions\n",
    "training_df_test['tfidf_centroid_pred'] = None\n",
    "\n",
    "for row in tqdm(range(training_df_test.shape[0])): #for each mail\n",
    "    # == Search for some metadata and data ====\n",
    "    \n",
    "    # Search for the sender\n",
    "    sender = training_df_test['sender'][row]\n",
    "    \n",
    "    #Search for all his previous emails sent (content + mid)\n",
    "    corpus = list(training_df_train[training_df_train['sender'] == sender]['body']) #we may have some doublons\n",
    "\n",
    "    #mids = emails_ids_per_sender_train[sender] #we have to keep them\n",
    "    mids = list(training_df_train[training_df_train['sender'] == sender]['mid'])\n",
    "    \n",
    "  \n",
    "    # == Clean the documents ====\n",
    "    corpus_clean = {}\n",
    "    for i, doc in enumerate(corpus):\n",
    "        lowers = doc.lower()\n",
    "        corpus_clean[mids[i]] = lowers\n",
    "\n",
    "    # == TFIDF ====\n",
    "    #corpus\n",
    "    tfidf_matrix_sender = tfidf.fit_transform(corpus_clean.values())\n",
    "\n",
    "    # new document\n",
    "    new_doc = training_df_test['body'][row]\n",
    "    response = tfidf.transform([new_doc])\n",
    "    response\n",
    "    \n",
    "    # == Centroids ====\n",
    "        \n",
    "    #We search the centroids for each recipient of sender\n",
    "    centroid_recipient = {} #contains for each recipient its vector representation\n",
    "\n",
    "    for recipient, out in address_books_train[sender]:\n",
    "        mids_sender_recipient = mids_sender_to_recipient[sender, recipient]\n",
    "        mask_mid = [mids[i] in list(mids_sender_recipient) for i in range(len(mids))]\n",
    "\n",
    "        centroid_recipient[recipient] = np.sum(tfidf_matrix_sender.todense()[mask_mid], axis = 0)\n",
    "    \n",
    "    # == Similarity ====\n",
    "    \n",
    "    #We calcultate the score for each recipient (cosine similarity) \n",
    "    score_recipient = {}\n",
    "    for recipient, centroid in centroid_recipient.items():\n",
    "        score_recipient[recipient] = float(cosine_similarity(centroid,response)[0])\n",
    "    \n",
    "    sorted_score_recipient = sorted(score_recipient.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    \n",
    "    # == Prediction ====\n",
    "    training_df_test['tfidf_centroid_pred'][row] = [elt[0] for elt in sorted_score_recipient[:k]]\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian on email content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining ...\n",
      "\t 0.277s\n",
      "Lowering ...\n",
      "\t 0.078s\n",
      "Tokenizing ...\n",
      "\t 5.592s\n",
      "Steming ...\n",
      "\t 88.646s\n",
      "Counting ...\n",
      "\t 1.778s\n",
      "Filtering ...\n",
      "\t 0.565s\n"
     ]
    }
   ],
   "source": [
    "#Count the occurence of a word in all the data\n",
    "print(\"Joining ...\")\n",
    "start_time = time.time()\n",
    "all_bodies_train = ' '.join(training_df_train['body'])\n",
    "taken_time = time.time() - start_time\n",
    "print(\"\\t %.3fs\" %taken_time)\n",
    "\n",
    "print(\"Lowering ...\")\n",
    "start_time = time.time()\n",
    "lowers_train = all_bodies_train.lower()\n",
    "taken_time = time.time() - start_time\n",
    "print(\"\\t %.3fs\" %taken_time)\n",
    "\n",
    "print(\"Tokenizing ...\")\n",
    "start_time = time.time()\n",
    "tokens_train = tokenizer.tokenize(lowers_train)\n",
    "taken_time = time.time() - start_time\n",
    "print(\"\\t %.3fs\" %taken_time)\n",
    "\n",
    "print(\"Steming ...\")\n",
    "start_time = time.time()\n",
    "stemmed = stem_tokens(tokens_train)\n",
    "taken_time = time.time() - start_time\n",
    "print(\"\\t %.3fs\" %taken_time)\n",
    "\n",
    "print(\"Counting ...\")\n",
    "start_time = time.time()\n",
    "count_words_all_bodies_train = Counter(stemmed)\n",
    "taken_time = time.time() - start_time\n",
    "print(\"\\t %.3fs\" %taken_time)\n",
    "\n",
    "print(\"Filtering ...\")\n",
    "start_time = time.time()\n",
    "#filtered_tokens_train = [w for w in lowers_train if not w in stopwords.words('english')]\n",
    "for sw in stopwords.words('english'):\n",
    "    if sw in count_words_all_bodies_train.keys():\n",
    "        del count_words_all_bodies_train[sw]\n",
    "taken_time = time.time() - start_time\n",
    "print(\"\\t %.3fs\" %taken_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Count all the unique words (stem without stop words) in all the training train\n",
    "n_words_all_bodies_train = np.sum([value for key, value in count_words_all_bodies_train.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_words(body):\n",
    "    #Lowering\n",
    "    lower = body.lower()\n",
    "    \n",
    "    #Tokenizing\n",
    "    token = tokenizer.tokenize(lower)\n",
    "    \n",
    "    #Steming\n",
    "    stemmed = stem_tokens(token)\n",
    "\n",
    "    #Counting\n",
    "    count_words = Counter(stemmed)\n",
    "   \n",
    "    #Filtering\n",
    "    for sw in stopwords.words('english'):\n",
    "        if sw in count_words.keys():\n",
    "            del count_words[sw]\n",
    "            \n",
    "    #Sum of counts\n",
    "    n_words = np.sum([value for key, value in count_words.items()])\n",
    "    \n",
    "    return count_words, n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_body(body):\n",
    "    lower = body.lower()\n",
    "    token = tokenizer.tokenize(lower)\n",
    "    stemmed = stem_tokens(token)\n",
    "    return ' '.join(stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'orange'> **Question :** </font>Should we consider all the emails shared between S and R or only those sent by S to R for $\\mathbb{P}(w |R,S)$ ? option 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c..giron@enron.com'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['337771',\n",
       " '337990',\n",
       " '336843',\n",
       " '347881',\n",
       " '338090',\n",
       " '338288',\n",
       " '337838',\n",
       " '338088',\n",
       " '337880',\n",
       " '338525',\n",
       " '338103',\n",
       " '338501',\n",
       " '338201',\n",
       " '337885',\n",
       " '337978',\n",
       " '338777',\n",
       " '338062',\n",
       " '337861',\n",
       " '161798',\n",
       " '338608',\n",
       " '338096',\n",
       " '338237',\n",
       " '338252',\n",
       " '338392',\n",
       " '338534',\n",
       " '338193',\n",
       " '338044',\n",
       " '338487',\n",
       " '337977']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mids_sender_to_recipient[sender, rec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chris.germany@enron.com\n",
      "\t scott.goodell@enron.com\n",
      "\t victor.lamadrid@enron.com\n",
      "\t brenda.fletcher@enron.com\n",
      "\t robert.allwein@enron.com\n",
      "\t judy.townsend@enron.com\n",
      "\t joann.collins@enron.com\n",
      "\t dick.jenkins@enron.com\n",
      "\t dan.junek@enron.com\n",
      "\t beverly.beaty@enron.com\n",
      "\t victoria.versen@enron.com\n",
      "susan.scott@enron.com\n",
      "\t jeffery.fawcett@enron.com\n",
      "\t lorraine.lindberg@enron.com\n",
      "\t steven.harris@enron.com\n",
      "\t ehillegeist@hotmail.com\n",
      "\t ted.noble@enron.com\n",
      "\t monique.sanchez@enron.com\n",
      "\t mary.miller@enron.com\n",
      "\t kevin.hyatt@enron.com\n",
      "\t lisa.gillette@enron.com\n",
      "\t michelle.lokay@enron.com\n",
      "chris.dorland@enron.com\n",
      "\t dan.dorland@enron.com\n",
      "\t rlaird@natsource.ca\n",
      "\t mmolloy@oebi.com\n",
      "\t kdorland@titanelectric.com\n",
      "\t bgabrielson@cdnam.com\n",
      "\t ddorland@smednet.com\n",
      "\t kim.melodick@enron.com\n",
      "\t migeorge@deloitte.ca\n",
      "\t mike.cowan@enron.com\n",
      "\t keith.holst@enron.com\n",
      "c..giron@enron.com\n",
      "\t carole.frank@enron.com\n",
      "\t kristi.giron@cfisd.net\n",
      "\t dgiron1@pdq.net\n",
      "\t jason.wolfe@enron.com\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('jason.wolfe@enron.com', 'c..giron@enron.com')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-9ebb190727f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mall_mids_sender_to_rec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmids_sender_to_recipient\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msender\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mall_senders_train\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#if the rec has sent mail\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mall_mids_rec_to_sender\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmids_sender_to_recipient\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msender\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[0mall_mids_sender_rec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_mids_sender_to_rec\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mall_mids_rec_to_sender\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('jason.wolfe@enron.com', 'c..giron@enron.com')"
     ]
    }
   ],
   "source": [
    "#TOOOOOOO LOONG\n",
    "\n",
    "#early optimization is the root of all evil\n",
    "k=10\n",
    "# quid parameters => use the one given by the paper\n",
    "lmbd = 0.6\n",
    "gamma = 0.2\n",
    "beta = 0.2\n",
    "\n",
    "#We use a stochastic approach : max(25%, 100) mids\n",
    "\n",
    "#Make some predictions\n",
    "training_df_test['bayes_mail'] = None\n",
    "N = 10 #training_df_test.shape[0]\n",
    "## WARNING : We use a subset for the moment\n",
    "\n",
    "for row in range(N): #for each mail\n",
    "    start_time = time.time()\n",
    "    sender = training_df_test['sender'][row]\n",
    "    print(sender)\n",
    "    body = training_df_test['body'][row]\n",
    "    cleaned_body = clean_body(body)\n",
    "    n_words_body = len(cleaned_body.split(' '))\n",
    "    taken_time = time.time() - start_time\n",
    "    #print('Acc√®s aux donn√©es : %.3fs' %(taken_time))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    #Recipients considered : those whom already receive a mail from the sender\n",
    "    recipients = [elt[0] for elt in address_books_train[sender]] # to test for a next version : (TODO) all_users_train\n",
    "    taken_time = time.time() - start_time\n",
    "    #print('Trouver les recipients possibles : %.3fs' %(taken_time))\n",
    "    \n",
    "    score_recipients = {}\n",
    "    \n",
    "    # == Compute P(w) ====\n",
    "    #already done =)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    #mails received and sent by the sender\n",
    "    mids_sent_sender = emails_ids_per_sender_train[sender]\n",
    "    if sender in mids_received_by_user_train.keys(): #if the sender has received at least one mail\n",
    "        mids_received_sender = mids_received_by_user_train[sender]\n",
    "        all_mids_sender = list(set(mids_received_sender + mids_sent_sender)) #do not count double self mail\n",
    "    else: #the sender sent but never received ...\n",
    "        all_mids_sender = mids_sent_sender\n",
    "        \n",
    "    #We choose some mids\n",
    "    n_mids_sender = np.minimum(np.maximum(100, round(0.25*len(all_mids_sender))), len(all_mids_sender))\n",
    "    all_mids_sender = list(np.random.choice(all_mids_sender, n_mids_sender, replace=False))\n",
    "    \n",
    "    taken_time = time.time() - start_time\n",
    "    #print('Trouver les mails s&r du sender : %.3fs' %(taken_time))\n",
    "    ## WARNING :We use a subset for the moment\n",
    "\n",
    "    min_recipients = min(10, len(recipients))\n",
    "    for rec in recipients[:min_recipients]:\n",
    "        print('\\t', rec)\n",
    "        # == Compute P(w|R) ====\n",
    "        \n",
    "        start_time = time.time()\n",
    "        #search for all mids of received (and sent if they exist) mails\n",
    "        mids_received_rec = mids_received_by_user_train[rec]\n",
    "        if rec in all_senders_train:\n",
    "            mids_sent_rec = emails_ids_per_sender_train[rec] #works only if the rec is also a sender\n",
    "            all_mids_rec = list(set(mids_received_rec + mids_sent_rec)) #do not count double self mail\n",
    "        else : \n",
    "            all_mids_rec = mids_received_rec\n",
    "            \n",
    "        #We choose some mids\n",
    "        n_mids_rec = np.minimum(np.maximum(100, round(0.25*len(all_mids_rec))), len(all_mids_rec))\n",
    "        all_mids_rec = list(np.random.choice(all_mids_rec, n_mids_rec, replace=False))\n",
    "    \n",
    "        taken_time = time.time() - start_time\n",
    "        #print('Trouver les mids re√ßus par le rec : %.3fs' %(taken_time))\n",
    "    \n",
    "        start_time = time.time()\n",
    "        #take all body of these mids\n",
    "        bodies_rec = ' '.join(training_df_train[(training_df_train['mid']).isin(all_mids_rec)]['body'])\n",
    "        count_words_rec, n_words_rec = count_words(bodies_rec)        \n",
    "        taken_time = time.time() - start_time\n",
    "        #print('Compter les mots dans les textes re√ßus et envoy√©s par le rec : %.3fs' %(taken_time))\n",
    "    \n",
    "        # == Compute P(w|R,S) ====\n",
    "        start_time = time.time()\n",
    "        #search for all mids exchange between the sender and the recipient\n",
    "        all_mids_sender_to_rec = mids_sender_to_recipient[sender, rec]\n",
    "        if rec in all_senders_train: #if the rec has sent mail TO THE SENDER !s\n",
    "            all_mids_rec_to_sender = mids_sender_to_recipient[rec, sender]\n",
    "            all_mids_sender_rec = list(set(all_mids_sender_to_rec + all_mids_rec_to_sender))\n",
    "        else:\n",
    "            all_mids_sender_rec = all_mids_sender_to_rec\n",
    "        #all_mids_sender_rec = list(set(all_mids_rec + all_mids_sender))\n",
    "        taken_time = time.time() - start_time\n",
    "        #print('Trouver les mails envoy√©s et/ou re√ßus par le sender et le rec : %.3fs' %(taken_time))\n",
    "    \n",
    "        start_time = time.time()\n",
    "        #take all body of these mids\n",
    "        bodies_sender_rec = ' '.join(training_df_train[(training_df_train['mid']).isin(all_mids_sender_rec)]['body'])\n",
    "        count_words_sender_rec, n_words_sender_rec = count_words(bodies_sender_rec)\n",
    "        taken_time = time.time() - start_time\n",
    "        #print('Compter les mots dans le corpus sender+rec : %.3fs' %(taken_time))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        # == Compute the score ====\n",
    "        score = 0\n",
    "        ## WARNING : We use a sum instead of a product otherwise the score is 0\n",
    "        \n",
    "        for word in cleaned_body.split(' '):\n",
    "            #print('word', word, '\\t SR', count_words_sender_rec[word], '\\t R', count_words_rec[word], '\\t all', count_words_all_bodies_train[word], '\\t score', score)\n",
    "            #print('sub : lmbd', count_words_sender_rec[word]/n_words_sender_rec, '\\t gamma', count_words_rec[word]/n_words_rec, '\\t beta', count_words_all_bodies_train[word]/n_words_all_bodies_train)\n",
    "            score += lmbd * count_words_sender_rec[word]/n_words_sender_rec +\\\n",
    "            gamma * count_words_rec[word]/n_words_rec +\\\n",
    "            beta * count_words_all_bodies_train[word]/n_words_all_bodies_train\n",
    "        \n",
    "        score_recipients[rec] = score\n",
    "        taken_time = time.time() - start_time\n",
    "        #print('Calculer le score pour un rec : %.3fs' %(taken_time))\n",
    "    \n",
    "    sorted_score_recipients = sorted(score_recipients.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    training_df_test['bayes_mail'][row] = [key for key,value in sorted_score_recipients[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('jason.wolfe@enron.com', 'c..giron@enron.com')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-fb9378d0627f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmids_sender_to_recipient\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msender\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: ('jason.wolfe@enron.com', 'c..giron@enron.com')"
     ]
    }
   ],
   "source": [
    "mids_sender_to_recipient[rec, sender]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sylvia.campos@enron.com', 0.55105088847236361),\n",
       " ('mary.franklin@enron.com', 0.50585441700903844),\n",
       " ('scott.neal@enron.com', 0.50383260386359963),\n",
       " ('brenda.fletcher@enron.com', 0.50026374475220559),\n",
       " ('sherry.anastas@enron.com', 0.49611748989650784),\n",
       " ('robert.allwein@enron.com', 0.49590089555674738),\n",
       " ('joan.veselack@enron.com', 0.49263073449156203),\n",
       " ('david.oliver@enron.com', 0.48991475444619098),\n",
       " ('steve.gillespie@enron.com', 0.48343162975078174),\n",
       " ('joe.casas@enron.com', 0.4808259311265588),\n",
       " ('katherine.kelly@enron.com', 0.47910407521466869),\n",
       " ('mark.breese@enron.com', 0.47892588096941269),\n",
       " ('alvin.thompson@enron.com', 0.47846733432987387),\n",
       " ('darla.saucier@enron.com', 0.47560218744287691),\n",
       " ('jessie.patterson@enron.com', 0.47371871889252232),\n",
       " ('sabra.dinari@enron.com', 0.47323510707556604),\n",
       " ('chris.germany@enron.com', 0.46891930510311713),\n",
       " ('marlene.hilliard@enron.com', 0.46796567268535),\n",
       " ('molly.lafuze@enron.com', 0.46769835872981708),\n",
       " ('dick.jenkins@enron.com', 0.46529847555504994),\n",
       " ('victor.lamadrid@enron.com', 0.46265837643586283),\n",
       " ('bperron@columbiaenergy.com', 0.46177404340554529),\n",
       " ('briant.baker@enron.com', 0.46148746878403268),\n",
       " ('clarissa.garcia@enron.com', 0.46132677357910462),\n",
       " ('tricia.bowen@enron.com', 0.45872379595103158),\n",
       " ('robin.barbe@enron.com', 0.45755156505471545),\n",
       " ('beverly.beaty@enron.com', 0.45669378008562267),\n",
       " ('kate.fraser@enron.com', 0.45606615146886387),\n",
       " ('molly.johnson@enron.com', 0.45544956834763117),\n",
       " ('crystal.hyde@enron.com', 0.45528134974930767),\n",
       " ('victoria.versen@enron.com', 0.45369712781673055),\n",
       " ('jim.homco@enron.com', 0.45175243824542582),\n",
       " ('meredith.mitchell@enron.com', 0.4503102213615281),\n",
       " ('scott.goodell@enron.com', 0.4495323501719547),\n",
       " ('marde.driscoll@enron.com', 0.44843655178065972),\n",
       " ('dan.junek@enron.com', 0.44501841824959143),\n",
       " ('cindy.vachuska@enron.com', 0.44426263897733415),\n",
       " ('sarah.mulholland@enron.com', 0.44340697296949927),\n",
       " ('jeffrey.porter@enron.com', 0.43707055978697412),\n",
       " ('joann.collins@enron.com', 0.43417926446346522),\n",
       " ('scott.hendrickson@enron.com', 0.42694245979526152),\n",
       " ('jesse.villarreal@enron.com', 0.42625859919295234),\n",
       " ('john.hodge@enron.com', 0.42558358063010387),\n",
       " ('angie.zeman@enron.com', 0.42502210070211927),\n",
       " ('kimat.singla@enron.com', 0.42488331890643433),\n",
       " ('cdalpho@columbiaenergygroup.com', 0.42213074330063516),\n",
       " ('edward.terry@enron.com', 0.42119425139576483),\n",
       " ('john.singer@enron.com', 0.42034117417355688),\n",
       " ('judy.townsend@enron.com', 0.42018858598317604),\n",
       " ('colleen.sullivan@enron.com', 0.41820749916073907),\n",
       " ('jporte1@columbiaenergygroup.com', 0.41751231816252382),\n",
       " ('dkinney@columbiaenergygroup.com', 0.41414670152162447),\n",
       " ('anita.patton@enron.com', 0.41259480020552869),\n",
       " ('mgermany@ch2m.com', 0.38767263280839148),\n",
       " ('trogg522@aol.com', 0.38659624754270111),\n",
       " ('germanj@basf-corp.com', 0.3820679394696469),\n",
       " ('ingrid.immer@williams.com', 0.38140881730093795),\n",
       " ('joni.veselack@neg.pge.com', 0.37985753005964462),\n",
       " ('8777208398.4891940@pagenetmessage.net', 0.36647246015326579),\n",
       " ('wdgermanyjr@dow.com', 0.33354949679777796)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_score_recipients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>sender</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipients</th>\n",
       "      <th>random_pred</th>\n",
       "      <th>random_pred_address_book</th>\n",
       "      <th>freq_pred</th>\n",
       "      <th>weighted_freq_pred</th>\n",
       "      <th>name_freq_pred</th>\n",
       "      <th>bayes_mail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337773</td>\n",
       "      <td>chris.germany@enron.com</td>\n",
       "      <td>2000-03-08 10:05:00</td>\n",
       "      <td>Looks good.Stephanie Sever   03/08/2000 05:35 ...</td>\n",
       "      <td>[stephanie.sever@enron.com]</td>\n",
       "      <td>[javier.li@enron.com, downes.andrew@enron.com,...</td>\n",
       "      <td>[troy.denetsosie@enron.com, gloria.barkowsky@e...</td>\n",
       "      <td>[scott.goodell@enron.com, victor.lamadrid@enro...</td>\n",
       "      <td>[scott.goodell@enron.com, jim.homco@enron.com,...</td>\n",
       "      <td>[scott.goodell@enron.com, victor.lamadrid@enro...</td>\n",
       "      <td>[sylvia.campos@enron.com, mary.franklin@enron....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112428</td>\n",
       "      <td>susan.scott@enron.com</td>\n",
       "      <td>2001-05-04 12:02:26</td>\n",
       "      <td>oh, it s on!</td>\n",
       "      <td>[adriane.schultea@enron.com, misti.day@enron.c...</td>\n",
       "      <td>[dutch.quigley@enron.com, rick.suttle@enron.co...</td>\n",
       "      <td>[ashleastu@aol.com, emily.boon@msdw.com, davis...</td>\n",
       "      <td>[jeffery.fawcett@enron.com, lorraine.lindberg@...</td>\n",
       "      <td>[ted.noble@enron.com, ehillegeist@hotmail.com,...</td>\n",
       "      <td>[jeffery.fawcett@enron.com, lorraine.lindberg@...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>362746</td>\n",
       "      <td>chris.dorland@enron.com</td>\n",
       "      <td>2000-11-13 03:25:00</td>\n",
       "      <td>George has Oyster Creek coming back Nov. 25. W...</td>\n",
       "      <td>[ricardo.perez@enron.com]</td>\n",
       "      <td>[philip.conn@enron.com, carlos.choudri@csfb.co...</td>\n",
       "      <td>[ptrussell@acurasouthwest.com, dawn.doucet@enr...</td>\n",
       "      <td>[dan.dorland@enron.com, rlaird@natsource.ca, m...</td>\n",
       "      <td>[dan.dorland@enron.com, rlaird@natsource.ca, m...</td>\n",
       "      <td>[migeorge@deloitte.ca, dan.dorland@enron.com, ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333249</td>\n",
       "      <td>c..giron@enron.com</td>\n",
       "      <td>2000-07-24 03:17:00</td>\n",
       "      <td>Last Friday I was trying to get into my accoun...</td>\n",
       "      <td>[onepass@coair.com]</td>\n",
       "      <td>[roncarroll@bracepatt.com, kimberly.rizzi@enro...</td>\n",
       "      <td>[shona.wilson@enron.com, scott.t.crowell@us.cg...</td>\n",
       "      <td>[carole.frank@enron.com, kristi.giron@cfisd.ne...</td>\n",
       "      <td>[carole.frank@enron.com, dgiron1@pdq.net, kris...</td>\n",
       "      <td>[carole.frank@enron.com, kristi.giron@cfisd.ne...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>384123</td>\n",
       "      <td>eric.bass@enron.com</td>\n",
       "      <td>2000-08-17 06:53:00</td>\n",
       "      <td>I want to trade you a 4th, 6th and 8th round p...</td>\n",
       "      <td>[lqcolombo@aol.com]</td>\n",
       "      <td>[david.frost@enron.com, tomas.szamosvolgyi@enr...</td>\n",
       "      <td>[daphneco64@bigplanet.com, faith.killen@enron....</td>\n",
       "      <td>[bryan.hull@enron.com, matthew.lenhart@enron.c...</td>\n",
       "      <td>[shanna.husser@enron.com, jason.bass2@compaq.c...</td>\n",
       "      <td>[bryan.hull@enron.com, matthew.lenhart@enron.c...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mid                   sender                 date  \\\n",
       "0  337773  chris.germany@enron.com  2000-03-08 10:05:00   \n",
       "1  112428    susan.scott@enron.com  2001-05-04 12:02:26   \n",
       "2  362746  chris.dorland@enron.com  2000-11-13 03:25:00   \n",
       "3  333249       c..giron@enron.com  2000-07-24 03:17:00   \n",
       "4  384123      eric.bass@enron.com  2000-08-17 06:53:00   \n",
       "\n",
       "                                                body  \\\n",
       "0  Looks good.Stephanie Sever   03/08/2000 05:35 ...   \n",
       "1                                      oh, it s on!    \n",
       "2  George has Oyster Creek coming back Nov. 25. W...   \n",
       "3  Last Friday I was trying to get into my accoun...   \n",
       "4  I want to trade you a 4th, 6th and 8th round p...   \n",
       "\n",
       "                                          recipients  \\\n",
       "0                        [stephanie.sever@enron.com]   \n",
       "1  [adriane.schultea@enron.com, misti.day@enron.c...   \n",
       "2                          [ricardo.perez@enron.com]   \n",
       "3                                [onepass@coair.com]   \n",
       "4                                [lqcolombo@aol.com]   \n",
       "\n",
       "                                         random_pred  \\\n",
       "0  [javier.li@enron.com, downes.andrew@enron.com,...   \n",
       "1  [dutch.quigley@enron.com, rick.suttle@enron.co...   \n",
       "2  [philip.conn@enron.com, carlos.choudri@csfb.co...   \n",
       "3  [roncarroll@bracepatt.com, kimberly.rizzi@enro...   \n",
       "4  [david.frost@enron.com, tomas.szamosvolgyi@enr...   \n",
       "\n",
       "                            random_pred_address_book  \\\n",
       "0  [troy.denetsosie@enron.com, gloria.barkowsky@e...   \n",
       "1  [ashleastu@aol.com, emily.boon@msdw.com, davis...   \n",
       "2  [ptrussell@acurasouthwest.com, dawn.doucet@enr...   \n",
       "3  [shona.wilson@enron.com, scott.t.crowell@us.cg...   \n",
       "4  [daphneco64@bigplanet.com, faith.killen@enron....   \n",
       "\n",
       "                                           freq_pred  \\\n",
       "0  [scott.goodell@enron.com, victor.lamadrid@enro...   \n",
       "1  [jeffery.fawcett@enron.com, lorraine.lindberg@...   \n",
       "2  [dan.dorland@enron.com, rlaird@natsource.ca, m...   \n",
       "3  [carole.frank@enron.com, kristi.giron@cfisd.ne...   \n",
       "4  [bryan.hull@enron.com, matthew.lenhart@enron.c...   \n",
       "\n",
       "                                  weighted_freq_pred  \\\n",
       "0  [scott.goodell@enron.com, jim.homco@enron.com,...   \n",
       "1  [ted.noble@enron.com, ehillegeist@hotmail.com,...   \n",
       "2  [dan.dorland@enron.com, rlaird@natsource.ca, m...   \n",
       "3  [carole.frank@enron.com, dgiron1@pdq.net, kris...   \n",
       "4  [shanna.husser@enron.com, jason.bass2@compaq.c...   \n",
       "\n",
       "                                      name_freq_pred  \\\n",
       "0  [scott.goodell@enron.com, victor.lamadrid@enro...   \n",
       "1  [jeffery.fawcett@enron.com, lorraine.lindberg@...   \n",
       "2  [migeorge@deloitte.ca, dan.dorland@enron.com, ...   \n",
       "3  [carole.frank@enron.com, kristi.giron@cfisd.ne...   \n",
       "4  [bryan.hull@enron.com, matthew.lenhart@enron.c...   \n",
       "\n",
       "                                          bayes_mail  \n",
       "0  [sylvia.campos@enron.com, mary.franklin@enron....  \n",
       "1                                               None  \n",
       "2                                               None  \n",
       "3                                               None  \n",
       "4                                               None  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test the P@10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split the recipients to use kdd_mapk\n",
    "for row in range(training_df_test.shape[0]):\n",
    "    training_df_test['recipients'][row] = training_df_test['recipients'][row].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00059133944379846008"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAP@10 for random predictions\n",
    "mapk(training_df_test['recipients'], training_df_test['random_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.035544609675171736"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAP@10 for random predictions among the address book of each sender\n",
    "mapk(training_df_test['recipients'], training_df_test['random_pred_address_book'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28965128918339306"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAP@10 for frequency-based predictions\n",
    "mapk(training_df_test['recipients'], training_df_test['freq_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28366836937240913"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAP@10 for weighted-frequency-based predictions\n",
    "mapk(training_df_test['recipients'], training_df_test['weighted_freq_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29346892476722686"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAP@10 for name_frequency-based predictions\n",
    "mapk(training_df_test['recipients'], training_df_test['name_freq_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MAP@10 for TF-IDF centroids predictions (withour STEM ! for the moment)\n",
    "#mapk(training_df_test['recipients'], training_df_test['tfidf_centroid_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that in the dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Score for each prediction with random recommendation\n",
    "training_df_test['score_random'] = None\n",
    "\n",
    "for row in range(training_df_test.shape[0]): #for each mail\n",
    "    training_df_test['score_random'][row] = apk(training_df_test['recipients'][row], training_df_test['random_pred'][row], k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Score for each prediction with frequency-based recommendations \n",
    "training_df_test['score_freq'] = None\n",
    "\n",
    "for row in range(training_df_test.shape[0]): #for each mail\n",
    "    training_df_test['score_freq'][row] = apk(training_df_test['recipients'][row], training_df_test['freq_pred'][row], k=10)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application on the real test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    }
   ],
   "source": [
    "test_df = transform_dataset(test_info, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>sender</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284098</td>\n",
       "      <td>jonathan.mckay@enron.com</td>\n",
       "      <td>2001-11-02 05:25:29</td>\n",
       "      <td>How is everyone.....mother, child.........fath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272008</td>\n",
       "      <td>dutch.quigley@enron.com</td>\n",
       "      <td>2001-11-02 05:34:55</td>\n",
       "      <td>-----Original Message-----From: \\tWesner-Soon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49273</td>\n",
       "      <td>james.d.steffes@enron.com</td>\n",
       "      <td>2001-11-02 05:57:55</td>\n",
       "      <td>Janine -Ok for you to cover the whole country....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71901</td>\n",
       "      <td>kim.ward@enron.com</td>\n",
       "      <td>2001-11-02 06:10:47</td>\n",
       "      <td>when?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82354</td>\n",
       "      <td>barry.tycholiz@enron.com</td>\n",
       "      <td>2001-11-02 06:17:44</td>\n",
       "      <td>WOW.... I am positive that your beautiful wife...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mid                     sender                 date  \\\n",
       "0  284098   jonathan.mckay@enron.com  2001-11-02 05:25:29   \n",
       "1  272008    dutch.quigley@enron.com  2001-11-02 05:34:55   \n",
       "2   49273  james.d.steffes@enron.com  2001-11-02 05:57:55   \n",
       "3   71901         kim.ward@enron.com  2001-11-02 06:10:47   \n",
       "4   82354   barry.tycholiz@enron.com  2001-11-02 06:17:44   \n",
       "\n",
       "                                                body  \n",
       "0  How is everyone.....mother, child.........fath...  \n",
       "1   -----Original Message-----From: \\tWesner-Soon...  \n",
       "2  Janine -Ok for you to cover the whole country....  \n",
       "3                                              when?  \n",
       "4  WOW.... I am positive that your beautiful wife...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'name_freq_pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-06a27743dd29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mmid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mname_freq_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name_freq_pred'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mmy_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m','\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_freq_preds\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'UTF-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Mehdi\\Annexes\\PythonENSAE_v2\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1912\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1914\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Mehdi\\Annexes\\PythonENSAE_v2\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1919\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1921\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionaility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Mehdi\\Annexes\\PythonENSAE_v2\\python\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1088\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1090\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1091\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Mehdi\\Annexes\\PythonENSAE_v2\\python\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3101\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3102\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3103\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Mehdi\\Annexes\\PythonENSAE_v2\\python\\lib\\site-packages\\pandas\\core\\index.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   1690\u001b[0m                 raise ValueError('tolerance argument only valid if using pad, '\n\u001b[0;32m   1691\u001b[0m                                  'backfill or nearest lookups')\n\u001b[1;32m-> 1692\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m         indexer = self.get_indexer([key], method=method,\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:3979)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:3843)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12265)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12216)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'name_freq_pred'"
     ]
    }
   ],
   "source": [
    "#Prediction according to the frequency and the name (first word in the mail)\n",
    "\n",
    "\n",
    "with open(path_to_results + 'predictions_name_freq_.txt', 'wb') as my_file:\n",
    "    my_file.write(bytes('mid,recipients' + '\\n', 'UTF-8'))\n",
    "    for row in range(test_df.shape[0]):\n",
    "        mid = test_df['mid'][row]\n",
    "        name_freq_preds = test_df['name_freq_pred'][row]\n",
    "        my_file.write(bytes(str(mid) + ',' + ' '.join(name_freq_preds) + '\\n', 'UTF-8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ENSAE)",
   "language": "python",
   "name": "python_3_ensae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
