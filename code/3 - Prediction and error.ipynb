{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Advanced Learning for Text and Graph Data </h1>\n",
    "<b> Université Paris-Saclay - Master M2 Data Science - February/March 2017</b> <br>\n",
    "<i> Students : Peter Martigny & Mehdi Miah </i> <br>\n",
    "\n",
    "# Third part  : predict and measure the error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#our own modules\n",
    "from map_tools import * #functions computing mean average precision\n",
    "from handy_structures import *\n",
    "\n",
    "#common libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from tqdm import *\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#path to data and intermediate results\n",
    "path_to_data = \"..\\\\data\\\\\"\n",
    "path_to_results = \"..\\\\results\\\\\"\n",
    "\n",
    "## == open files ====\n",
    "\n",
    "#original data\n",
    "training_set = pd.read_csv(path_to_data + 'training_set.csv')\n",
    "training_info = pd.read_csv(path_to_data + 'training_info.csv', \n",
    "                            dtype = {'mid': object, 'date': object, 'body': object, 'recipients' : object})\n",
    "test_set = pd.read_csv(path_to_data + 'test_set.csv')\n",
    "test_info = pd.read_csv(path_to_data + 'test_info.csv',\n",
    "                        dtype = {'mid': object, 'date': object, 'body': object, 'recipients' : object})\n",
    "\n",
    "#intermediate data\n",
    "training_df = pd.read_csv(path_to_results + 'training_df.csv',\n",
    "                          dtype = {'mid': object, 'sender': object, 'date': object, 'body': object, 'recipients' : object})\n",
    "test_df = pd.read_csv(path_to_results + 'test_df.csv',\n",
    "                          dtype = {'mid': object, 'sender': object, 'date': object, 'body': object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>mids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>158713 158697 200301 158679 278595 298162 2002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amr.ibrahim@enron.com</td>\n",
       "      <td>215241 3437 215640 3506 191790 3517 3520 3562 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andrea.ring@enron.com</td>\n",
       "      <td>270705 270706 270707 270708 270709 270710 2707...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sylvia.hu@enron.com</td>\n",
       "      <td>111444 111422 183084 111412 111347 110883 1105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phillip.platter@enron.com</td>\n",
       "      <td>327074 327384 327385 264443 274124 274125 2741...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sender  \\\n",
       "0    karen.buckley@enron.com   \n",
       "1      amr.ibrahim@enron.com   \n",
       "2      andrea.ring@enron.com   \n",
       "3        sylvia.hu@enron.com   \n",
       "4  phillip.platter@enron.com   \n",
       "\n",
       "                                                mids  \n",
       "0  158713 158697 200301 158679 278595 298162 2002...  \n",
       "1  215241 3437 215640 3506 191790 3517 3520 3562 ...  \n",
       "2  270705 270706 270707 270708 270709 270710 2707...  \n",
       "3  111444 111422 183084 111412 111347 110883 1105...  \n",
       "4  327074 327384 327385 264443 274124 274125 2741...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>2000-07-25 08:14:00</td>\n",
       "      <td>Legal has been assessing the risks of doing bl...</td>\n",
       "      <td>robert.badeer@enron.com murray.o neil@enron.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>2000-08-03 02:56:00</td>\n",
       "      <td>Attached is a spreadsheet to estimate export f...</td>\n",
       "      <td>kim.ward@enron.com robert.badeer@enron.com mur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74</td>\n",
       "      <td>2000-08-15 05:37:00</td>\n",
       "      <td>Kevin/Bob: Here is a quick rundown on the cons...</td>\n",
       "      <td>robert.badeer@enron.com john.massey@enron.com ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80</td>\n",
       "      <td>2000-08-20 14:12:00</td>\n",
       "      <td>check this out and let everyone know what s up...</td>\n",
       "      <td>robert.badeer@enron.com jeff.richter@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>2000-08-22 08:17:00</td>\n",
       "      <td>Further to your letter to us (addressed to Mr....</td>\n",
       "      <td>pgillman@schiffhardin.com kamarlantes@calpx.co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mid                 date                                               body  \\\n",
       "0  60  2000-07-25 08:14:00  Legal has been assessing the risks of doing bl...   \n",
       "1  66  2000-08-03 02:56:00  Attached is a spreadsheet to estimate export f...   \n",
       "2  74  2000-08-15 05:37:00  Kevin/Bob: Here is a quick rundown on the cons...   \n",
       "3  80  2000-08-20 14:12:00  check this out and let everyone know what s up...   \n",
       "4  83  2000-08-22 08:17:00  Further to your letter to us (addressed to Mr....   \n",
       "\n",
       "                                          recipients  \n",
       "0  robert.badeer@enron.com murray.o neil@enron.co...  \n",
       "1  kim.ward@enron.com robert.badeer@enron.com mur...  \n",
       "2  robert.badeer@enron.com john.massey@enron.com ...  \n",
       "3     robert.badeer@enron.com jeff.richter@enron.com  \n",
       "4  pgillman@schiffhardin.com kamarlantes@calpx.co...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>mids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>298389 332383 298390 284071 366982 81773 81791...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amr.ibrahim@enron.com</td>\n",
       "      <td>48260 48465 50344 48268 50330 48237 189979 189...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andrea.ring@enron.com</td>\n",
       "      <td>366364 271168 271172 271167 271189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sylvia.hu@enron.com</td>\n",
       "      <td>134931 134856 233549 233517 134895 233584 3736...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phillip.platter@enron.com</td>\n",
       "      <td>274220 274225 274215 274223 274214 274207 2742...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sender  \\\n",
       "0    karen.buckley@enron.com   \n",
       "1      amr.ibrahim@enron.com   \n",
       "2      andrea.ring@enron.com   \n",
       "3        sylvia.hu@enron.com   \n",
       "4  phillip.platter@enron.com   \n",
       "\n",
       "                                                mids  \n",
       "0  298389 332383 298390 284071 366982 81773 81791...  \n",
       "1  48260 48465 50344 48268 50330 48237 189979 189...  \n",
       "2                 366364 271168 271172 271167 271189  \n",
       "3  134931 134856 233549 233517 134895 233584 3736...  \n",
       "4  274220 274225 274215 274223 274214 274207 2742...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1577</td>\n",
       "      <td>2001-11-19 06:59:51</td>\n",
       "      <td>Note:  Stocks of heating oil are very high for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1750</td>\n",
       "      <td>2002-03-05 08:46:57</td>\n",
       "      <td>Kevin Hyatt and I are going for \"sghetti\" at S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1916</td>\n",
       "      <td>2002-02-13 14:17:39</td>\n",
       "      <td>This was forwarded to me and it is funny. - Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2094</td>\n",
       "      <td>2002-01-22 11:33:56</td>\n",
       "      <td>I will be in to and happy to assist too.  I ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2205</td>\n",
       "      <td>2002-01-11 07:12:19</td>\n",
       "      <td>Thanks. I needed a morning chuckle.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mid                 date  \\\n",
       "0  1577  2001-11-19 06:59:51   \n",
       "1  1750  2002-03-05 08:46:57   \n",
       "2  1916  2002-02-13 14:17:39   \n",
       "3  2094  2002-01-22 11:33:56   \n",
       "4  2205  2002-01-11 07:12:19   \n",
       "\n",
       "                                                body  \n",
       "0  Note:  Stocks of heating oil are very high for...  \n",
       "1  Kevin Hyatt and I are going for \"sghetti\" at S...  \n",
       "2  This was forwarded to me and it is funny. - Wi...  \n",
       "3  I will be in to and happy to assist too.  I ma...  \n",
       "4                Thanks. I needed a morning chuckle.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>sender</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47361</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-08-26 22:16:36</td>\n",
       "      <td>The following reports have been waiting for yo...</td>\n",
       "      <td>kimberly.watson@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47362</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-08-27 22:21:02</td>\n",
       "      <td>The following reports have been waiting for yo...</td>\n",
       "      <td>kimberly.watson@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47363</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-08-28 22:25:35</td>\n",
       "      <td>The following reports have been waiting for yo...</td>\n",
       "      <td>kimberly.watson@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45909</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-09-13 22:24:08</td>\n",
       "      <td>Employee Name: Kimberly WatsonReport Name:   E...</td>\n",
       "      <td>kimberly.watson@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82030</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-09-17 09:24:00</td>\n",
       "      <td>The following expense report is ready for appr...</td>\n",
       "      <td>barry.tycholiz@enron.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mid                             sender                 date  \\\n",
       "0  47361  enron_update@concureworkplace.com  0001-08-26 22:16:36   \n",
       "1  47362  enron_update@concureworkplace.com  0001-08-27 22:21:02   \n",
       "2  47363  enron_update@concureworkplace.com  0001-08-28 22:25:35   \n",
       "3  45909  enron_update@concureworkplace.com  0001-09-13 22:24:08   \n",
       "4  82030  enron_update@concureworkplace.com  0001-09-17 09:24:00   \n",
       "\n",
       "                                                body  \\\n",
       "0  The following reports have been waiting for yo...   \n",
       "1  The following reports have been waiting for yo...   \n",
       "2  The following reports have been waiting for yo...   \n",
       "3  Employee Name: Kimberly WatsonReport Name:   E...   \n",
       "4  The following expense report is ready for appr...   \n",
       "\n",
       "                  recipients  \n",
       "0  kimberly.watson@enron.com  \n",
       "1  kimberly.watson@enron.com  \n",
       "2  kimberly.watson@enron.com  \n",
       "3  kimberly.watson@enron.com  \n",
       "4   barry.tycholiz@enron.com  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>sender</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284098</td>\n",
       "      <td>jonathan.mckay@enron.com</td>\n",
       "      <td>2001-11-02 05:25:29</td>\n",
       "      <td>How is everyone.....mother, child.........fath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272008</td>\n",
       "      <td>dutch.quigley@enron.com</td>\n",
       "      <td>2001-11-02 05:34:55</td>\n",
       "      <td>-----Original Message-----From: \\tWesner-Soon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49273</td>\n",
       "      <td>james.d.steffes@enron.com</td>\n",
       "      <td>2001-11-02 05:57:55</td>\n",
       "      <td>Janine -Ok for you to cover the whole country....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71901</td>\n",
       "      <td>kim.ward@enron.com</td>\n",
       "      <td>2001-11-02 06:10:47</td>\n",
       "      <td>when?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82354</td>\n",
       "      <td>barry.tycholiz@enron.com</td>\n",
       "      <td>2001-11-02 06:17:44</td>\n",
       "      <td>WOW.... I am positive that your beautiful wife...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mid                     sender                 date  \\\n",
       "0  284098   jonathan.mckay@enron.com  2001-11-02 05:25:29   \n",
       "1  272008    dutch.quigley@enron.com  2001-11-02 05:34:55   \n",
       "2   49273  james.d.steffes@enron.com  2001-11-02 05:57:55   \n",
       "3   71901         kim.ward@enron.com  2001-11-02 06:10:47   \n",
       "4   82354   barry.tycholiz@enron.com  2001-11-02 06:17:44   \n",
       "\n",
       "                                                body  \n",
       "0  How is everyone.....mother, child.........fath...  \n",
       "1   -----Original Message-----From: \\tWesner-Soon...  \n",
       "2  Janine -Ok for you to cover the whole country....  \n",
       "3                                              when?  \n",
       "4  WOW.... I am positive that your beautiful wife...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First way : temporal on all emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False :\n",
    "    #Temporal separation between training and test\n",
    "    # already time ordered\n",
    "    pct_train = 0.5\n",
    "    idx_separation = round(pct_train * training_info.shape[0])\n",
    "    mid_train = training_info['mid'][:idx_separation]\n",
    "    mid_test = training_info['mid'][idx_separation:]\n",
    "\n",
    "    # Separation in training_info\n",
    "    training_info_train = training_info[:idx_separation]\n",
    "    training_info_test = training_info[idx_separation:]\n",
    "\n",
    "    #Separation in training_set\n",
    "    training_set_train = training_set.copy()\n",
    "    training_set_test = training_set.copy()\n",
    "\n",
    "    for row in range(training_set_train.shape[0]):\n",
    "        mids = training_set_train['mids'][row].split(' ')\n",
    "        new_mid = list(set(mids) & set(mid_train))\n",
    "        training_set_train['mids'][row] = ' '.join(new_mid)\n",
    "\n",
    "    for row in range(training_set_test.shape[0]):\n",
    "        mids = training_set_test['mids'][row].split(' ')\n",
    "        new_mid = list(set(mids) & set(mid_test))\n",
    "        training_set_test['mids'][row] = ' '.join(new_mid)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    #dataframe\n",
    "    training_df_train = transform_dataset(training_info_train, training_set_train)\n",
    "    training_df_test = transform_dataset(training_info_test, training_set_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some users are in the test set and NOT in the train set : mike.carson@enron.com, vkaminski@aol.com and christina.valdez@enron.com !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second way : pure randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    training_all_senders = training_set['sender'].get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if True : \n",
    "    # Separation in training_df\n",
    "    training_df_train, training_df_test = train_test_split(training_df, test_size=0.2, random_state=0)\n",
    "\n",
    "    training_df_train = training_df_train.reset_index(drop=True)\n",
    "    training_df_test = training_df_test.reset_index(drop=True)\n",
    "\n",
    "    mid_train = training_df_train['mid']\n",
    "    mid_test = training_df_test['mid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    # Construction of _set with for each sender, the list of emails\n",
    "\n",
    "    #Training\n",
    "    training_set_train = pd.DataFrame()\n",
    "    for sender in tqdm(training_all_senders):\n",
    "        mids = training_df_train[training_df_train['sender'] == sender]['mid'].values.tolist()\n",
    "        mids = ' '.join(list(map(str, mids)))\n",
    "        training_set_train_sender = pd.DataFrame({'sender':[sender], 'mids': [mids]})\n",
    "\n",
    "        training_set_train = training_set_train.append(training_set_train_sender)\n",
    "\n",
    "    #reorder the columns\n",
    "    training_set_train = training_set_train.reindex_axis(['sender', 'mids'], axis = 1)\n",
    "\n",
    "    #add clean index\n",
    "    training_set_train = training_set_train.reset_index(drop=True)\n",
    "\n",
    "    #Test\n",
    "    training_set_test = pd.DataFrame()\n",
    "    for sender in tqdm(training_all_senders):\n",
    "        mids = training_df_test[training_df_test['sender'] == sender]['mid'].values.tolist()\n",
    "        mids = ' '.join(list(map(str, mids)))\n",
    "        training_set_test_sender = pd.DataFrame({'sender':[sender], 'mids': [mids]})\n",
    "\n",
    "        training_set_test = training_set_test.append(training_set_test_sender)\n",
    "\n",
    "    #reorder the columns\n",
    "    training_set_test = training_set_test.reindex_axis(['sender', 'mids'], axis = 1)\n",
    "\n",
    "    #add clean index\n",
    "    training_set_test = training_set_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    # Construction of _info with info about each mail\n",
    "\n",
    "    #Training\n",
    "    mids_train = training_df_train.mid.get_values().astype('str')\n",
    "    training_info_train = training_info[(training_info['mid']).isin(mids_train)]\n",
    "\n",
    "    #Test\n",
    "    mids_test = training_df_test.mid.get_values().astype('str')\n",
    "    training_info_test = training_info[(training_info['mid']).isin(mids_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### third way : temporal by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    training_all_senders = training_set['sender'].get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    def split_data_v3(training_df, training_all_senders, pct_train = 0.8):\n",
    "        #Initialisation of the two dataframe for learning and testing\n",
    "        training_df_train = pd.DataFrame()\n",
    "        training_df_test = pd.DataFrame()\n",
    "\n",
    "        #We fill the values by taking the oldest emails in the train and the newest in test dataframe\n",
    "        for sender in tqdm(training_all_senders):\n",
    "            #dataframe with all emails sent by the sender\n",
    "            training_df_sender = training_df[training_df['sender'] == sender] #non void\n",
    "            limit = round(pct_train * training_df_sender.shape[0])\n",
    "\n",
    "            training_df_train_sender = training_df_sender[:limit]\n",
    "            training_df_test_sender = training_df_sender[limit:]\n",
    "\n",
    "            training_df_train = training_df_train.append(training_df_train_sender)\n",
    "            training_df_test = training_df_test.append(training_df_test_sender)\n",
    "\n",
    "        #put the right index\n",
    "        training_df_train = training_df_train.reset_index(drop=True)\n",
    "        training_df_test = training_df_test.reset_index(drop=True)\n",
    "\n",
    "        return training_df_train, training_df_test\n",
    "\n",
    "    training_df_train, training_df_test = split_data_v3(training_df, training_all_senders, pct_train = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to generate _info and _set dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Construction of _set with for each sender, the list of emails\n",
    "\n",
    "    #Training\n",
    "    training_set_train = pd.DataFrame()\n",
    "    for sender in tqdm(training_all_senders):\n",
    "        mids = training_df_train[training_df_train['sender'] == sender]['mid'].values.tolist()\n",
    "        mids = ' '.join(list(map(str, mids)))\n",
    "        training_set_train_sender = pd.DataFrame({'sender':[sender], 'mids': [mids]})\n",
    "\n",
    "        training_set_train = training_set_train.append(training_set_train_sender)\n",
    "\n",
    "    #reorder the columns\n",
    "    training_set_train = training_set_train.reindex_axis(['sender', 'mids'], axis = 1)\n",
    "\n",
    "    #add clean index\n",
    "    training_set_train = training_set_train.reset_index(drop=True)\n",
    "\n",
    "    #Test\n",
    "    training_set_test = pd.DataFrame()\n",
    "    for sender in tqdm(training_all_senders):\n",
    "        mids = training_df_test[training_df_test['sender'] == sender]['mid'].values.tolist()\n",
    "        mids = ' '.join(list(map(str, mids)))\n",
    "        training_set_test_sender = pd.DataFrame({'sender':[sender], 'mids': [mids]})\n",
    "\n",
    "        training_set_test = training_set_test.append(training_set_test_sender)\n",
    "\n",
    "    #reorder the columns\n",
    "    training_set_test = training_set_test.reindex_axis(['sender', 'mids'], axis = 1)\n",
    "\n",
    "    #add clean index\n",
    "    training_set_test = training_set_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sender</th>\n",
       "      <th>mids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>karen.buckley@enron.com</td>\n",
       "      <td>390472 298372 158472 158594 365523 366836 1597...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amr.ibrahim@enron.com</td>\n",
       "      <td>191629 3437 3664 191797 215241 50792 190011 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andrea.ring@enron.com</td>\n",
       "      <td>270813 365818 270708 270747 270769 270768 2707...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sylvia.hu@enron.com</td>\n",
       "      <td>37547 35813 38516 38487 111444 108576 106923 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phillip.platter@enron.com</td>\n",
       "      <td>274158 274121 274186 274134 274162 274135 2741...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sender  \\\n",
       "0    karen.buckley@enron.com   \n",
       "1      amr.ibrahim@enron.com   \n",
       "2      andrea.ring@enron.com   \n",
       "3        sylvia.hu@enron.com   \n",
       "4  phillip.platter@enron.com   \n",
       "\n",
       "                                                mids  \n",
       "0  390472 298372 158472 158594 365523 366836 1597...  \n",
       "1  191629 3437 3664 191797 215241 50792 190011 18...  \n",
       "2  270813 365818 270708 270747 270769 270768 2707...  \n",
       "3  37547 35813 38516 38487 111444 108576 106923 2...  \n",
       "4  274158 274121 274186 274134 274162 274135 2741...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    # Construction of _info with info about each mail\n",
    "\n",
    "    #Training\n",
    "    mids_train = training_df_train.mid.get_values().astype('str')\n",
    "    training_info_train = training_info[(training_info['mid']).isin(mids_train)]\n",
    "\n",
    "    #Test\n",
    "    mids_test = training_df_test.mid.get_values().astype('str')\n",
    "    training_info_test = training_info[(training_info['mid']).isin(mids_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337707</td>\n",
       "      <td>2000-02-29 08:19:00</td>\n",
       "      <td>Not yet, still trying to be creative in what I...</td>\n",
       "      <td>clayton.vernon@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>299551</td>\n",
       "      <td>2001-04-02 13:07:00</td>\n",
       "      <td>I have just been informed that our P&amp;L was ove...</td>\n",
       "      <td>john.lavorato@enron.com louise.kitchen@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>368521</td>\n",
       "      <td>2001-04-11 04:13:00</td>\n",
       "      <td>Here is another one...---------------------- F...</td>\n",
       "      <td>bob.hall@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>182846</td>\n",
       "      <td>1999-07-23 10:57:00</td>\n",
       "      <td>Did you receive my voice mail yesterday about ...</td>\n",
       "      <td>rod.nelson@enron.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276472</td>\n",
       "      <td>2001-03-26 09:01:00</td>\n",
       "      <td>Dad,Attached is Brett s baseball schedule.  I ...</td>\n",
       "      <td>cneal@bluegate.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mid                 date  \\\n",
       "0  337707  2000-02-29 08:19:00   \n",
       "1  299551  2001-04-02 13:07:00   \n",
       "2  368521  2001-04-11 04:13:00   \n",
       "3  182846  1999-07-23 10:57:00   \n",
       "4  276472  2001-03-26 09:01:00   \n",
       "\n",
       "                                                body  \\\n",
       "0  Not yet, still trying to be creative in what I...   \n",
       "1  I have just been informed that our P&L was ove...   \n",
       "2  Here is another one...---------------------- F...   \n",
       "3  Did you receive my voice mail yesterday about ...   \n",
       "4  Dad,Attached is Brett s baseball schedule.  I ...   \n",
       "\n",
       "                                         recipients  \n",
       "0                          clayton.vernon@enron.com  \n",
       "1  john.lavorato@enron.com louise.kitchen@enron.com  \n",
       "2                                bob.hall@enron.com  \n",
       "3                              rod.nelson@enron.com  \n",
       "4                                cneal@bluegate.com  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_info_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check on cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some sanity test : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SANITY CHECK ON training\n",
      "Number of emails in the full dataframe : 43613 \t _info : 43613 \t _set : 43613 \n",
      "\n",
      "SANITY CHECK ON training for train\n",
      "Number of emails in the full dataframe : 34890 \t _info : 34890 \t _set : 34890 \n",
      "\n",
      "SANITY CHECK ON training for test\n",
      "Number of emails in the full dataframe : 8723 \t _info : 8723 \t _set : 8723 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## == Check on the number of email in each part ====\n",
    "n_senders = 125\n",
    "\n",
    "def sanity_check_n_emails(dataset_df, dataset_info, dataset_set, name):\n",
    "    n_mails_dataset_df = dataset_df.shape[0]\n",
    "    n_mails_dataset_info = dataset_info.shape[0]\n",
    "    n_mails_dataset_set = np.sum([len(dataset_set.mids[i].split(' ')) for i in range(n_senders)])\n",
    "    print('SANITY CHECK ON ' + name)\n",
    "    print('Number of emails in the full dataframe : %.0f \\t _info : %.0f \\t _set : %.0f \\n' \n",
    "          %(n_mails_dataset_df, n_mails_dataset_info, n_mails_dataset_set))\n",
    "\n",
    "#In the training (train + test)\n",
    "sanity_check_n_emails(training_df, training_info, training_set, \"training\")\n",
    "\n",
    "#In the train\n",
    "sanity_check_n_emails(training_df_train, training_info_train ,training_set_train , \"training for train\")\n",
    "\n",
    "#In the test\n",
    "sanity_check_n_emails(training_df_test, training_info_test ,training_set_test, \"training for test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some handy structures on the train of cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    }
   ],
   "source": [
    "address_books_train = get_address_books(training_info_train, training_set_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save all unique sender names\n",
    "emails_ids_per_sender_train = get_mids_per_sender(training_set_train)\n",
    "all_senders_train = emails_ids_per_sender_train.keys()\n",
    "\n",
    "# save all unique recipient names    \n",
    "all_recs_train = list(set([elt[0] for sublist in address_books_train.values() for elt in sublist]))\n",
    "\n",
    "# save all unique user names \n",
    "all_users_train = []\n",
    "all_users_train.extend(all_senders_train)\n",
    "all_users_train.extend(all_recs_train)\n",
    "all_users_train = list(set(all_users_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    def get_mid_sender_recipient(dataset_df, sender, recipient):\n",
    "\n",
    "        mask_sender = (sender == dataset_df.sender)\n",
    "        mask_recipient = [recipient in dataset_df.recipients[i] for i in range(dataset_df.shape[0])]\n",
    "\n",
    "        mask = mask_sender & mask_recipient\n",
    "\n",
    "        return dataset_df['mid'][mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random predictions on all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HERE THE PREDICTION WILL ONLY DEPENDS ON THE SENDER !\n",
    "def predictions_random_per_sender(dataset_set, all_users, k=10):\n",
    "\n",
    "    # will contain email ids, predictions for random baseline\n",
    "    predictions_random_per_sender = {}\n",
    "\n",
    "    for index, row in dataset_set.iterrows():\n",
    "        name_ids = row.tolist() #sender + all ones mails)\n",
    "        sender = name_ids[0]\n",
    "\n",
    "        predictions_random_per_sender[sender] = random.sample(all_users, k)\n",
    "        \n",
    "    return predictions_random_per_sender    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make some predictions\n",
    "predictions_random = predictions_random_per_sender(training_set_train, all_users_train)\n",
    "\n",
    "#Fill the dataframe\n",
    "training_df_test['random_pred'] = None\n",
    "for row in range(training_df_test.shape[0]): #for each mail\n",
    "    sender = training_df_test['sender'][row]\n",
    "\n",
    "    #random prediction\n",
    "    training_df_test['random_pred'][row] = predictions_random[sender] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>sender</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipients</th>\n",
       "      <th>random_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27781</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-10-04 08:34:46</td>\n",
       "      <td>The following expense report is ready for appr...</td>\n",
       "      <td>mark.whitt@enron.com</td>\n",
       "      <td>[gbn@bus.utexas.edu, clay.harris@enron.com, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201622</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-10-15 15:18:32</td>\n",
       "      <td>The Payment status has changed on the followin...</td>\n",
       "      <td>mark.mcconnell@enron.com</td>\n",
       "      <td>[gbn@bus.utexas.edu, clay.harris@enron.com, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201623</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-10-15 15:18:32</td>\n",
       "      <td>The Approval status has changed on the followi...</td>\n",
       "      <td>mark.mcconnell@enron.com</td>\n",
       "      <td>[gbn@bus.utexas.edu, clay.harris@enron.com, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201624</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-10-15 15:18:35</td>\n",
       "      <td>The Approval status has changed on the followi...</td>\n",
       "      <td>mark.mcconnell@enron.com</td>\n",
       "      <td>[gbn@bus.utexas.edu, clay.harris@enron.com, ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82795</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-10-17 13:06:55</td>\n",
       "      <td>The following expense report is ready for appr...</td>\n",
       "      <td>barry.tycholiz@enron.com</td>\n",
       "      <td>[gbn@bus.utexas.edu, clay.harris@enron.com, ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mid                             sender                 date  \\\n",
       "0   27781  enron_update@concureworkplace.com  0001-10-04 08:34:46   \n",
       "1  201622  enron_update@concureworkplace.com  0001-10-15 15:18:32   \n",
       "2  201623  enron_update@concureworkplace.com  0001-10-15 15:18:32   \n",
       "3  201624  enron_update@concureworkplace.com  0001-10-15 15:18:35   \n",
       "4   82795  enron_update@concureworkplace.com  0001-10-17 13:06:55   \n",
       "\n",
       "                                                body  \\\n",
       "0  The following expense report is ready for appr...   \n",
       "1  The Payment status has changed on the followin...   \n",
       "2  The Approval status has changed on the followi...   \n",
       "3  The Approval status has changed on the followi...   \n",
       "4  The following expense report is ready for appr...   \n",
       "\n",
       "                 recipients                                        random_pred  \n",
       "0      mark.whitt@enron.com  [gbn@bus.utexas.edu, clay.harris@enron.com, ca...  \n",
       "1  mark.mcconnell@enron.com  [gbn@bus.utexas.edu, clay.harris@enron.com, ca...  \n",
       "2  mark.mcconnell@enron.com  [gbn@bus.utexas.edu, clay.harris@enron.com, ca...  \n",
       "3  mark.mcconnell@enron.com  [gbn@bus.utexas.edu, clay.harris@enron.com, ca...  \n",
       "4  barry.tycholiz@enron.com  [gbn@bus.utexas.edu, clay.harris@enron.com, ca...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random predictions on the address book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HERE THE PREDICTION WILL ONLY DEPENDS ON THE SENDER !\n",
    "\n",
    "def predictions_random_address_book_per_sender(dataset_set, address_books, k=10):\n",
    "    '''\n",
    "    Recommends recipients randomly amongst the addresss books of the sender\n",
    "    The number of recipients may be under k if the sender has not sent enough emails.\n",
    "    '''\n",
    "    # will contain email ids, predictions for random baseline\n",
    "    predictions_random_address_book_per_sender = {}\n",
    "    for index, row in dataset_set.iterrows():\n",
    "        name_ids = row.tolist() #sender + all ones mails)\n",
    "        sender = name_ids[0]\n",
    "\n",
    "        recipients_of_the_sender = [elt[0] for elt in address_books[sender]]\n",
    "        n_recipients_of_the_sender = len(recipients_of_the_sender)\n",
    "        \n",
    "        predictions_random_address_book_per_sender[sender] = random.sample(recipients_of_the_sender, min(k,n_recipients_of_the_sender))\n",
    "    return predictions_random_address_book_per_sender    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make some predictions\n",
    "predictions_random_address_book = predictions_random_address_book_per_sender(training_set_train, address_books_train)\n",
    "\n",
    "#Fill the dataframe\n",
    "training_df_test['random_pred_address_book'] = None\n",
    "for row in range(training_df_test.shape[0]): #for each mail\n",
    "    sender = training_df_test['sender'][row]\n",
    "\n",
    "    #random prediction\n",
    "    training_df_test['random_pred_address_book'][row] = predictions_random_address_book[sender]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency based predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HERE THE PREDICTION WILL ONLY DEPENDS ON THE SENDER !\n",
    "def predictions_frequency_per_sender(dataset_set, address_books, k = 10):\n",
    "\n",
    "    # will contain email ids, predictions for frequency baseline\n",
    "    predictions_frequency_per_sender = {}\n",
    "\n",
    "    for index, row in dataset_set.iterrows():\n",
    "        name_ids = row.tolist() #sender + all ones mails\n",
    "        sender = name_ids[0]\n",
    "\n",
    "        # select k most frequent recipients for the user\n",
    "        predictions_frequency_per_sender[sender] = [elt[0] for elt in address_books[sender][:k]]\n",
    "        \n",
    "    return predictions_frequency_per_sender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make some predictions\n",
    "predictions_frequency = predictions_frequency_per_sender(training_set_train, address_books_train)\n",
    "\n",
    "#Fill the dataframe\n",
    "training_df_test['freq_pred'] = None\n",
    "for row in range(training_df_test.shape[0]): #for each mail\n",
    "    sender = training_df_test['sender'][row]\n",
    "\n",
    "    #random prediction\n",
    "    training_df_test['freq_pred'][row] = predictions_frequency[sender]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted frequency-based predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weighted_score(dataset_df):\n",
    "    '''\n",
    "    Computes a score between the sender and the recipient\n",
    "    score(sender, recipient) = sum_{emails from sender to recipients} 1/(number of recipients in the email)\n",
    "    \n",
    "    == Input ==\n",
    "    a dataframe with all the data\n",
    "    == Output ==\n",
    "    a dictionnary where the key is the sender and the value the tuple (recipient, score)\n",
    "    '''\n",
    "    #Learning phase\n",
    "    dict_weight = {} #the key is (sender, recipient)\n",
    "    for row in tqdm(range(dataset_df.shape[0])):\n",
    "\n",
    "        sender = dataset_df['sender'][row]\n",
    "        recipients = dataset_df['recipients'][row].split(' ')\n",
    "        n_recipients = len(recipients)\n",
    "\n",
    "        for rec in recipients: #for each recipients\n",
    "            key = sender, rec\n",
    "            if key in dict_weight : \n",
    "                dict_weight[key] =  dict_weight[key] + 1./n_recipients\n",
    "            else:\n",
    "                dict_weight[key] = 1./n_recipients\n",
    "\n",
    "    #The right order\n",
    "    weight_sender_recipient = {} #the key is (sender)\n",
    "    for key, value in dict_weight.items():\n",
    "        sender = key[0]\n",
    "        rec = key[1]\n",
    "\n",
    "        if sender in weight_sender_recipient:\n",
    "            weight_sender_recipient[sender] = sorted(weight_sender_recipient[sender] + [(rec,value)], key=operator.itemgetter(1), reverse = True)      \n",
    "        else:\n",
    "            weight_sender_recipient[sender] = [(rec,value)]\n",
    "            \n",
    "    return dict_weight, weight_sender_recipient      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    }
   ],
   "source": [
    "dict_weight, weight_sender_recipient = get_weighted_score(training_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make some predictions\n",
    "training_df_test['weighted_freq_pred'] = None\n",
    "k=10\n",
    "\n",
    "#Testing phase\n",
    "for row in range(training_df_test.shape[0]): #for each mail\n",
    "    sender = training_df_test['sender'][row]\n",
    "\n",
    "    #random prediction\n",
    "    training_df_test['weighted_freq_pred'][row] = [elt[0] for elt in weight_sender_recipient[sender][:k]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looks for a name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_recipients_from_name(name, all_users):\n",
    "    '''\n",
    "    Gives 0 or 1 recipient email address whose name is the one given is the input\n",
    "    \n",
    "    == Input ==\n",
    "    name : a string with the name one is looking for\n",
    "    all_users : a list of names, where the name is looked for, ordered by preference / score\n",
    "    == Output ==\n",
    "    if name is found, an email address\n",
    "    '''\n",
    "    \n",
    "    if((len(name) > 3)): #remove 'it'\n",
    "        for rec in all_users : \n",
    "            rec_name = rec.split('@')[0] #the part before the @\n",
    "            score = str.find(rec_name, name.lower()) #returns -1 if the name is not in the email address, otherwise its position\n",
    "            if score > -1: #a corresponding email address has been found\n",
    "                return [rec]\n",
    "        return [] #no corresponding email address\n",
    "    return [] #the given name is too short "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mark.fischer@enron.com']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recipients_from_name('Mark', all_users_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    }
   ],
   "source": [
    "#Make some predictions\n",
    "training_df_test['name_freq_pred'] = None\n",
    "k=10\n",
    "\n",
    "#Testing phase\n",
    "for row in tqdm(range(training_df_test.shape[0])): #for each mail\n",
    "    sender = training_df_test['sender'][row]\n",
    "    name_rec = training_df_test['body'][row].split(' ')[:1][0]\n",
    "\n",
    "    #remove some nasty character\n",
    "    #name_rec = str(name_rec).replace(',', '') \n",
    "    \n",
    "    #find the possible recipients from this first word, amongst those the sender has already sent an email\n",
    "    address_book_sender = [elt[0] for elt in address_books_train[sender]] #ordered by the frequency ! \n",
    "    \n",
    "    recipients_from_name = get_recipients_from_name(name_rec, address_book_sender)\n",
    "\n",
    "    #add the frequent recipients\n",
    "    recipients_from_frequency = predictions_frequency[sender]\n",
    "    \n",
    "    #cumul\n",
    "    result = recipients_from_name\n",
    "    result.extend(x for x in recipients_from_frequency if x not in result)\n",
    "\n",
    "    training_df_test['name_freq_pred'][row] = result[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>sender</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipients</th>\n",
       "      <th>random_pred</th>\n",
       "      <th>random_pred_address_book</th>\n",
       "      <th>freq_pred</th>\n",
       "      <th>weighted_freq_pred</th>\n",
       "      <th>name_freq_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27781</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-10-04 08:34:46</td>\n",
       "      <td>The following expense report is ready for appr...</td>\n",
       "      <td>mark.whitt@enron.com</td>\n",
       "      <td>[gbn@bus.utexas.edu, clay.harris@enron.com, ca...</td>\n",
       "      <td>[joe.stepenovitch@enron.com, tmartin@enron.com...</td>\n",
       "      <td>[richard.shapiro@enron.com, rick.buy@enron.com...</td>\n",
       "      <td>[n, o, r, e, ., c, m, @, a, i]</td>\n",
       "      <td>[richard.shapiro@enron.com, rick.buy@enron.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201622</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-10-15 15:18:32</td>\n",
       "      <td>The Payment status has changed on the followin...</td>\n",
       "      <td>mark.mcconnell@enron.com</td>\n",
       "      <td>[gbn@bus.utexas.edu, clay.harris@enron.com, ca...</td>\n",
       "      <td>[joe.stepenovitch@enron.com, tmartin@enron.com...</td>\n",
       "      <td>[richard.shapiro@enron.com, rick.buy@enron.com...</td>\n",
       "      <td>[n, o, r, e, ., c, m, @, a, i]</td>\n",
       "      <td>[richard.shapiro@enron.com, rick.buy@enron.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201623</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-10-15 15:18:32</td>\n",
       "      <td>The Approval status has changed on the followi...</td>\n",
       "      <td>mark.mcconnell@enron.com</td>\n",
       "      <td>[gbn@bus.utexas.edu, clay.harris@enron.com, ca...</td>\n",
       "      <td>[joe.stepenovitch@enron.com, tmartin@enron.com...</td>\n",
       "      <td>[richard.shapiro@enron.com, rick.buy@enron.com...</td>\n",
       "      <td>[n, o, r, e, ., c, m, @, a, i]</td>\n",
       "      <td>[richard.shapiro@enron.com, rick.buy@enron.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201624</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-10-15 15:18:35</td>\n",
       "      <td>The Approval status has changed on the followi...</td>\n",
       "      <td>mark.mcconnell@enron.com</td>\n",
       "      <td>[gbn@bus.utexas.edu, clay.harris@enron.com, ca...</td>\n",
       "      <td>[joe.stepenovitch@enron.com, tmartin@enron.com...</td>\n",
       "      <td>[richard.shapiro@enron.com, rick.buy@enron.com...</td>\n",
       "      <td>[n, o, r, e, ., c, m, @, a, i]</td>\n",
       "      <td>[richard.shapiro@enron.com, rick.buy@enron.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82795</td>\n",
       "      <td>enron_update@concureworkplace.com</td>\n",
       "      <td>0001-10-17 13:06:55</td>\n",
       "      <td>The following expense report is ready for appr...</td>\n",
       "      <td>barry.tycholiz@enron.com</td>\n",
       "      <td>[gbn@bus.utexas.edu, clay.harris@enron.com, ca...</td>\n",
       "      <td>[joe.stepenovitch@enron.com, tmartin@enron.com...</td>\n",
       "      <td>[richard.shapiro@enron.com, rick.buy@enron.com...</td>\n",
       "      <td>[n, o, r, e, ., c, m, @, a, i]</td>\n",
       "      <td>[richard.shapiro@enron.com, rick.buy@enron.com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mid                             sender                 date  \\\n",
       "0   27781  enron_update@concureworkplace.com  0001-10-04 08:34:46   \n",
       "1  201622  enron_update@concureworkplace.com  0001-10-15 15:18:32   \n",
       "2  201623  enron_update@concureworkplace.com  0001-10-15 15:18:32   \n",
       "3  201624  enron_update@concureworkplace.com  0001-10-15 15:18:35   \n",
       "4   82795  enron_update@concureworkplace.com  0001-10-17 13:06:55   \n",
       "\n",
       "                                                body  \\\n",
       "0  The following expense report is ready for appr...   \n",
       "1  The Payment status has changed on the followin...   \n",
       "2  The Approval status has changed on the followi...   \n",
       "3  The Approval status has changed on the followi...   \n",
       "4  The following expense report is ready for appr...   \n",
       "\n",
       "                 recipients  \\\n",
       "0      mark.whitt@enron.com   \n",
       "1  mark.mcconnell@enron.com   \n",
       "2  mark.mcconnell@enron.com   \n",
       "3  mark.mcconnell@enron.com   \n",
       "4  barry.tycholiz@enron.com   \n",
       "\n",
       "                                         random_pred  \\\n",
       "0  [gbn@bus.utexas.edu, clay.harris@enron.com, ca...   \n",
       "1  [gbn@bus.utexas.edu, clay.harris@enron.com, ca...   \n",
       "2  [gbn@bus.utexas.edu, clay.harris@enron.com, ca...   \n",
       "3  [gbn@bus.utexas.edu, clay.harris@enron.com, ca...   \n",
       "4  [gbn@bus.utexas.edu, clay.harris@enron.com, ca...   \n",
       "\n",
       "                            random_pred_address_book  \\\n",
       "0  [joe.stepenovitch@enron.com, tmartin@enron.com...   \n",
       "1  [joe.stepenovitch@enron.com, tmartin@enron.com...   \n",
       "2  [joe.stepenovitch@enron.com, tmartin@enron.com...   \n",
       "3  [joe.stepenovitch@enron.com, tmartin@enron.com...   \n",
       "4  [joe.stepenovitch@enron.com, tmartin@enron.com...   \n",
       "\n",
       "                                           freq_pred  \\\n",
       "0  [richard.shapiro@enron.com, rick.buy@enron.com...   \n",
       "1  [richard.shapiro@enron.com, rick.buy@enron.com...   \n",
       "2  [richard.shapiro@enron.com, rick.buy@enron.com...   \n",
       "3  [richard.shapiro@enron.com, rick.buy@enron.com...   \n",
       "4  [richard.shapiro@enron.com, rick.buy@enron.com...   \n",
       "\n",
       "               weighted_freq_pred  \\\n",
       "0  [n, o, r, e, ., c, m, @, a, i]   \n",
       "1  [n, o, r, e, ., c, m, @, a, i]   \n",
       "2  [n, o, r, e, ., c, m, @, a, i]   \n",
       "3  [n, o, r, e, ., c, m, @, a, i]   \n",
       "4  [n, o, r, e, ., c, m, @, a, i]   \n",
       "\n",
       "                                      name_freq_pred  \n",
       "0  [richard.shapiro@enron.com, rick.buy@enron.com...  \n",
       "1  [richard.shapiro@enron.com, rick.buy@enron.com...  \n",
       "2  [richard.shapiro@enron.com, rick.buy@enron.com...  \n",
       "3  [richard.shapiro@enron.com, rick.buy@enron.com...  \n",
       "4  [richard.shapiro@enron.com, rick.buy@enron.com...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer(analyzer='word', stop_words = 'english', norm = 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_mids_sender_to_recipient(address_books, dataset_df):\n",
    "    '''\n",
    "    Computes the list of mids for each couple (sender, recipient)\n",
    "    '''\n",
    "    #a new dictionnary\n",
    "    mids_sender_to_recipient = {}\n",
    "    \n",
    "    #all the senders\n",
    "    all_senders = address_books_train.keys()\n",
    "    \n",
    "    for sender in tqdm(all_senders):\n",
    "        #the mails sent by the sender\n",
    "        mask_sender = (sender == dataset_df.sender)\n",
    "        sub_dataset_df = dataset_df[mask_sender]\n",
    "        sub_dataset_df = sub_dataset_df.reset_index(drop=True)\n",
    "        \n",
    "        rec_out = address_books[sender]\n",
    "        for rec, out in rec_out: \n",
    "\n",
    "            #we search amongst them, those sent to the recipient\n",
    "            mask_recipient = [rec in sub_dataset_df.recipients[i] for i in range(sub_dataset_df.shape[0])]\n",
    "\n",
    "            #we save the result\n",
    "            mids_sender_to_recipient[(sender, rec)] = sub_dataset_df['mid'][mask_recipient].values.tolist()\n",
    "        \n",
    "    return mids_sender_to_recipient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    }
   ],
   "source": [
    "mids_sender_to_recipient = get_mids_sender_to_recipient(address_books_train, training_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['28043', '27895', '27898', '27985', '28076']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mids_sender_to_recipient['enron_update@concureworkplace.com', 'mark.whitt@enron.com'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens)\n",
    "    return stems\n",
    "\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                 | 0/8723 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chris.germany@enron.com\n",
      "1968\n",
      "1968\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mehdi\\Annexes\\PythonENSAE_v2\\python\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py:318: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n",
      "  out = N.ndarray.__getitem__(self, index)\n"
     ]
    }
   ],
   "source": [
    "#early optimization is the root of all evil\n",
    "k=10\n",
    "#Make some predictions\n",
    "training_df_test['tfidf_centroid_pred'] = None\n",
    "\n",
    "for row in tqdm(range(training_df_test.shape[0])): #for each mail\n",
    "    # Search for the sender\n",
    "    sender = training_df_test['sender'][row]\n",
    "    print(sender)\n",
    "    \n",
    "    #Search for all his previous emails sent (content + mid)\n",
    "    corpus = list(training_df_train[training_df_train['sender'] == sender]['body']) #we may have some doublons\n",
    "    print(len(corpus))\n",
    "    #mids = emails_ids_per_sender_train[sender] #we have to keep them\n",
    "    mids = list(training_df_train[training_df_train['sender'] == sender]['mid'])\n",
    "    print(len(mids))\n",
    "    \n",
    "    #DO NOT : Add the new document in the test\n",
    "    #corpus = docs # + [training_df_test['body'][row]]\n",
    "    #print(len(documents))\n",
    "    \n",
    "    #Clean the documents\n",
    "    corpus_clean = {}\n",
    "    for i, doc in enumerate(corpus):\n",
    "        lowers = doc.lower()\n",
    "        #no_punctuation = lowers#.translate(string.punctuation)\n",
    "        corpus_clean[mids[i]] = lowers\n",
    "\n",
    "    # == TFIDF ====\n",
    "    #corpus\n",
    "    \n",
    "    tfidf_matrix_sender = tfidf.fit_transform(corpus_clean.values())\n",
    "\n",
    "    # new document\n",
    "    new_doc = training_df_test['body'][row]\n",
    "    response = tfidf.transform([new_doc])\n",
    "    response\n",
    "        \n",
    "    #We search the centroids for each recipient of sender\n",
    "    centroid_recipient = {} #contains for each recipient its vector representation\n",
    "\n",
    "    kmin = min(20, len(address_books_train[sender]))\n",
    "    for recipient, out in address_books_train[sender][:kmin]:\n",
    "        mids_sender_recipient = mids_sender_to_recipient[sender, recipient]\n",
    "        mask_mid = [mids[i] in list(mids_sender_recipient) for i in range(len(mids))]\n",
    "\n",
    "        centroid_recipient[recipient] = np.sum(tfidf_matrix_sender.todense()[mask_mid], axis = 0)\n",
    "\n",
    "    print(len(centroid_recipient)) \n",
    "    \n",
    "    #We calcultate the score for each recipient (cosine similarity) \n",
    "    score_recipient = {}\n",
    "    for recipient, centroid in centroid_recipient.items():\n",
    "        score_recipient[recipient] = float(cosine_similarity(centroid,response)[0])\n",
    "    \n",
    "    sorted_score_recipient = sorted(score_recipient.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    \n",
    "    #prediction\n",
    "    training_df_test['tfidf_centroid_pred'][row] = [elt[0] for elt in sorted_score_recipient[:k]]\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>sender</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipients</th>\n",
       "      <th>random_pred</th>\n",
       "      <th>freq_pred</th>\n",
       "      <th>weighted_freq_pred</th>\n",
       "      <th>name_freq_pred</th>\n",
       "      <th>tfidf_centroid_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337773</td>\n",
       "      <td>chris.germany@enron.com</td>\n",
       "      <td>2000-03-08 10:05:00</td>\n",
       "      <td>Looks good.Stephanie Sever   03/08/2000 05:35 ...</td>\n",
       "      <td>[stephanie.sever@enron.com]</td>\n",
       "      <td>[rudy.elizondo@enron.com, tony.harris@enron.co...</td>\n",
       "      <td>[scott.goodell@enron.com, victor.lamadrid@enro...</td>\n",
       "      <td>[scott.goodell@enron.com, jim.homco@enron.com,...</td>\n",
       "      <td>[scott.goodell@enron.com, victor.lamadrid@enro...</td>\n",
       "      <td>[scott.goodell@enron.com, victor.lamadrid@enro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mid                   sender                 date  \\\n",
       "0  337773  chris.germany@enron.com  2000-03-08 10:05:00   \n",
       "\n",
       "                                                body  \\\n",
       "0  Looks good.Stephanie Sever   03/08/2000 05:35 ...   \n",
       "\n",
       "                    recipients  \\\n",
       "0  [stephanie.sever@enron.com]   \n",
       "\n",
       "                                         random_pred  \\\n",
       "0  [rudy.elizondo@enron.com, tony.harris@enron.co...   \n",
       "\n",
       "                                           freq_pred  \\\n",
       "0  [scott.goodell@enron.com, victor.lamadrid@enro...   \n",
       "\n",
       "                                  weighted_freq_pred  \\\n",
       "0  [scott.goodell@enron.com, jim.homco@enron.com,...   \n",
       "\n",
       "                                      name_freq_pred  \\\n",
       "0  [scott.goodell@enron.com, victor.lamadrid@enro...   \n",
       "\n",
       "                                 tfidf_centroid_pred  \n",
       "0  [scott.goodell@enron.com, victor.lamadrid@enro...  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ======== False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                 | 0/8723 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chris.germany@enron.com\n",
      "1968\n",
      "1968\n",
      "1969\n"
     ]
    }
   ],
   "source": [
    "#early optimization is the root of all evil\n",
    "k=10\n",
    "#Make some predictions\n",
    "training_df_test['tfidf_centroid_pred'] = None\n",
    "\n",
    "for row in tqdm(range(training_df_test.shape[0])): #for each mail\n",
    "    # Search for the sender\n",
    "    sender = training_df_test['sender'][row]\n",
    "    print(sender)\n",
    "    \n",
    "    #Search for all his previous emails sent (content + mid)\n",
    "    docs = list(training_df_train[training_df_train['sender'] == sender]['body']) #we may have some doublons\n",
    "    print(len(docs))\n",
    "    #mids = emails_ids_per_sender_train[sender] #we have to keep them\n",
    "    mids = list(training_df_train[training_df_train['sender'] == sender]['mid'])\n",
    "    print(len(mids))\n",
    "    \n",
    "    #Add the new document in the test\n",
    "    documents = docs + [training_df_test['body'][row]]\n",
    "    print(len(documents))\n",
    "    \n",
    "    #Lowerize the text\n",
    "    for i, doc in enumerate(documents):\n",
    "        documents[i] = doc.lower()\n",
    "    \n",
    "    #Stemming the whole corpus\n",
    "    for text in documents:\n",
    "        text_stem = []\n",
    "        for word in text.split(' '):\n",
    "            word_stem = porter_stemmer.stem(word)\n",
    "            text_stem.append(word_stem) \n",
    "            text_stem2 = ' '.join(text_stem)\n",
    "        break\n",
    "    break\n",
    "    \n",
    "    '''\n",
    "    We have forgetten to use stems !\n",
    "    '''\n",
    "    #We make a TF-IDF on all these documents\n",
    "    tfidf_matrix_sender = tf.fit_transform(documents)\n",
    "   \n",
    "    #We search the centroids for each recipient of sender\n",
    "    centroid_recipient = {} #contains for each recipient its vector representation\n",
    "\n",
    "    for recipient, out in address_books_train[sender]:\n",
    "        mids_sender_recipient = mids_sender_to_recipient[sender, recipient]\n",
    "        \n",
    "        mask_mid = [mids[i] in list(mids_sender_recipient) for i in range(len(mids))]\n",
    "        mask_mid = mask_mid + [False] #for the new document\n",
    "\n",
    "        centroid_recipient[recipient] = np.sum(tfidf_matrix_sender.todense()[mask_mid], axis = 0)\n",
    "\n",
    "    print(len(centroid_recipient))    \n",
    "    #We calcultate the score for each recipient (cosine similarity) \n",
    "    score_recipient = {}\n",
    "    for recipient, centroid in centroid_recipient.items():\n",
    "        score_recipient[recipient] = float(cosine_similarity(centroid,tfidf_matrix_sender.todense()[-1,:])[0])\n",
    "    \n",
    "    sorted_score_recipient = sorted(score_recipient.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    \n",
    "    #prediction\n",
    "    training_df_test['tfidf_centroid_pred'][row] = [elt[0] for elt in sorted_score_recipient[:k]]\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test the P@10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>sender</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "      <th>recipients</th>\n",
       "      <th>random_pred</th>\n",
       "      <th>freq_pred</th>\n",
       "      <th>weighted_freq_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337773</td>\n",
       "      <td>chris.germany@enron.com</td>\n",
       "      <td>2000-03-08 10:05:00</td>\n",
       "      <td>Looks good.Stephanie Sever   03/08/2000 05:35 ...</td>\n",
       "      <td>[stephanie.sever@enron.com]</td>\n",
       "      <td>[rudy.elizondo@enron.com, tony.harris@enron.co...</td>\n",
       "      <td>[scott.goodell@enron.com, victor.lamadrid@enro...</td>\n",
       "      <td>[o, n, e, ., r, m, c, a, @, l]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112428</td>\n",
       "      <td>susan.scott@enron.com</td>\n",
       "      <td>2001-05-04 12:02:26</td>\n",
       "      <td>oh, it s on!</td>\n",
       "      <td>[adriane.schultea@enron.com, misti.day@enron.c...</td>\n",
       "      <td>[tbroderi@czn.com, antoine.pierre@enron.com, 9...</td>\n",
       "      <td>[jeffery.fawcett@enron.com, lorraine.lindberg@...</td>\n",
       "      <td>[o, e, n, ., m, c, r, a, l, @]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>362746</td>\n",
       "      <td>chris.dorland@enron.com</td>\n",
       "      <td>2000-11-13 03:25:00</td>\n",
       "      <td>George has Oyster Creek coming back Nov. 25. W...</td>\n",
       "      <td>[ricardo.perez@enron.com]</td>\n",
       "      <td>[stephen.wood@enron.com, jim.white@las-cruces....</td>\n",
       "      <td>[dan.dorland@enron.com, rlaird@natsource.ca, k...</td>\n",
       "      <td>[o, n, e, r, ., c, m, a, l, @]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333249</td>\n",
       "      <td>c..giron@enron.com</td>\n",
       "      <td>2000-07-24 03:17:00</td>\n",
       "      <td>Last Friday I was trying to get into my accoun...</td>\n",
       "      <td>[onepass@coair.com]</td>\n",
       "      <td>[us@enron.com, patrick.mulvany@enron.com, vire...</td>\n",
       "      <td>[carole.frank@enron.com, kristi.giron@cfisd.ne...</td>\n",
       "      <td>[n, o, r, e, ., c, m, i, a, @]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>384123</td>\n",
       "      <td>eric.bass@enron.com</td>\n",
       "      <td>2000-08-17 06:53:00</td>\n",
       "      <td>I want to trade you a 4th, 6th and 8th round p...</td>\n",
       "      <td>[lqcolombo@aol.com]</td>\n",
       "      <td>[cheryl.dudley@enron.com, diana.scholtes@enron...</td>\n",
       "      <td>[bryan.hull@enron.com, matthew.lenhart@enron.c...</td>\n",
       "      <td>[n, o, e, ., a, r, m, c, @, s]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mid                   sender                 date  \\\n",
       "0  337773  chris.germany@enron.com  2000-03-08 10:05:00   \n",
       "1  112428    susan.scott@enron.com  2001-05-04 12:02:26   \n",
       "2  362746  chris.dorland@enron.com  2000-11-13 03:25:00   \n",
       "3  333249       c..giron@enron.com  2000-07-24 03:17:00   \n",
       "4  384123      eric.bass@enron.com  2000-08-17 06:53:00   \n",
       "\n",
       "                                                body  \\\n",
       "0  Looks good.Stephanie Sever   03/08/2000 05:35 ...   \n",
       "1                                      oh, it s on!    \n",
       "2  George has Oyster Creek coming back Nov. 25. W...   \n",
       "3  Last Friday I was trying to get into my accoun...   \n",
       "4  I want to trade you a 4th, 6th and 8th round p...   \n",
       "\n",
       "                                          recipients  \\\n",
       "0                        [stephanie.sever@enron.com]   \n",
       "1  [adriane.schultea@enron.com, misti.day@enron.c...   \n",
       "2                          [ricardo.perez@enron.com]   \n",
       "3                                [onepass@coair.com]   \n",
       "4                                [lqcolombo@aol.com]   \n",
       "\n",
       "                                         random_pred  \\\n",
       "0  [rudy.elizondo@enron.com, tony.harris@enron.co...   \n",
       "1  [tbroderi@czn.com, antoine.pierre@enron.com, 9...   \n",
       "2  [stephen.wood@enron.com, jim.white@las-cruces....   \n",
       "3  [us@enron.com, patrick.mulvany@enron.com, vire...   \n",
       "4  [cheryl.dudley@enron.com, diana.scholtes@enron...   \n",
       "\n",
       "                                           freq_pred  \\\n",
       "0  [scott.goodell@enron.com, victor.lamadrid@enro...   \n",
       "1  [jeffery.fawcett@enron.com, lorraine.lindberg@...   \n",
       "2  [dan.dorland@enron.com, rlaird@natsource.ca, k...   \n",
       "3  [carole.frank@enron.com, kristi.giron@cfisd.ne...   \n",
       "4  [bryan.hull@enron.com, matthew.lenhart@enron.c...   \n",
       "\n",
       "               weighted_freq_pred  \n",
       "0  [o, n, e, ., r, m, c, a, @, l]  \n",
       "1  [o, e, n, ., m, c, r, a, l, @]  \n",
       "2  [o, n, e, r, ., c, m, a, l, @]  \n",
       "3  [n, o, r, e, ., c, m, i, a, @]  \n",
       "4  [n, o, e, ., a, r, m, c, @, s]  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split the recipients to use kdd_mapk\n",
    "for row in range(training_df_test.shape[0]):\n",
    "    training_df_test['recipients'][row] = training_df_test['recipients'][row].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00061432874957465129"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAP@10 for random predictions\n",
    "mapk(training_df_test['recipients'], training_df_test['random_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034742122198211191"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAP@10 for random predictions among the address book of each sender\n",
    "mapk(training_df_test['recipients'], training_df_test['random_pred_address_book'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28947520561737972"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAP@10 for frequency-based predictions\n",
    "mapk(training_df_test['recipients'], training_df_test['freq_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28388610397538971"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAP@10 for weighted-frequency-based predictions\n",
    "mapk(training_df_test['recipients'], training_df_test['weighted_freq_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29334070469169998"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAP@10 for name_frequency-based predictions\n",
    "mapk(training_df_test['recipients'], training_df_test['name_freq_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-9681995df0cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# MAP@10 for TF-IDF centroids predictions (withour STEM ! for the moment)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmapk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_df_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'recipients'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_df_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tfidf_centroid_pred'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Mehdi\\Documents\\Paris-Saclay\\Learning for Text and Data Graph\\Data challenge - Linagora\\Project\\code\\map_tools.py\u001b[0m in \u001b[0;36mmapk\u001b[1;34m(actual, predicted, k)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mapk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Mehdi\\Documents\\Paris-Saclay\\Learning for Text and Data Graph\\Data challenge - Linagora\\Project\\code\\map_tools.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mapk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Mehdi\\Documents\\Paris-Saclay\\Learning for Text and Data Graph\\Data challenge - Linagora\\Project\\code\\map_tools.py\u001b[0m in \u001b[0;36mapk\u001b[1;34m(actual, predicted, k)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0maverage\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0mat\u001b[0m \u001b[0mk\u001b[0m \u001b[0mover\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mlists\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \"\"\"\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# MAP@10 for TF-IDF centroids predictions (withour STEM ! for the moment)\n",
    "mapk(training_df_test['recipients'], training_df_test['tfidf_centroid_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that in the dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Score for each prediction with random recommendation\n",
    "training_df_test['score_random'] = None\n",
    "\n",
    "for row in range(training_df_test.shape[0]): #for each mail\n",
    "    training_df_test['score_random'][row] = apk(training_df_test['recipients'][row], training_df_test['random_pred'][row], k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Score for each prediction with frequency-based recommendations \n",
    "training_df_test['score_freq'] = None\n",
    "\n",
    "for row in range(training_df_test.shape[0]): #for each mail\n",
    "    training_df_test['score_freq'][row] = apk(training_df_test['recipients'][row], training_df_test['freq_pred'][row], k=10)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application on the real test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    }
   ],
   "source": [
    "test_df = transform_dataset(test_info, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mid</th>\n",
       "      <th>sender</th>\n",
       "      <th>date</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284098</td>\n",
       "      <td>jonathan.mckay@enron.com</td>\n",
       "      <td>2001-11-02 05:25:29</td>\n",
       "      <td>How is everyone.....mother, child.........fath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272008</td>\n",
       "      <td>dutch.quigley@enron.com</td>\n",
       "      <td>2001-11-02 05:34:55</td>\n",
       "      <td>-----Original Message-----From: \\tWesner-Soon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49273</td>\n",
       "      <td>james.d.steffes@enron.com</td>\n",
       "      <td>2001-11-02 05:57:55</td>\n",
       "      <td>Janine -Ok for you to cover the whole country....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71901</td>\n",
       "      <td>kim.ward@enron.com</td>\n",
       "      <td>2001-11-02 06:10:47</td>\n",
       "      <td>when?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82354</td>\n",
       "      <td>barry.tycholiz@enron.com</td>\n",
       "      <td>2001-11-02 06:17:44</td>\n",
       "      <td>WOW.... I am positive that your beautiful wife...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mid                     sender                 date  \\\n",
       "0  284098   jonathan.mckay@enron.com  2001-11-02 05:25:29   \n",
       "1  272008    dutch.quigley@enron.com  2001-11-02 05:34:55   \n",
       "2   49273  james.d.steffes@enron.com  2001-11-02 05:57:55   \n",
       "3   71901         kim.ward@enron.com  2001-11-02 06:10:47   \n",
       "4   82354   barry.tycholiz@enron.com  2001-11-02 06:17:44   \n",
       "\n",
       "                                                body  \n",
       "0  How is everyone.....mother, child.........fath...  \n",
       "1   -----Original Message-----From: \\tWesner-Soon...  \n",
       "2  Janine -Ok for you to cover the whole country....  \n",
       "3                                              when?  \n",
       "4  WOW.... I am positive that your beautiful wife...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'name_freq_pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-06a27743dd29>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mmid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mname_freq_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name_freq_pred'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mmy_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m','\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_freq_preds\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'UTF-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Mehdi\\Annexes\\PythonENSAE_v2\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1912\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1913\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1914\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Mehdi\\Annexes\\PythonENSAE_v2\\python\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1919\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1921\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionaility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Mehdi\\Annexes\\PythonENSAE_v2\\python\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1088\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1090\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1091\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Mehdi\\Annexes\\PythonENSAE_v2\\python\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3101\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3102\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3103\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Mehdi\\Annexes\\PythonENSAE_v2\\python\\lib\\site-packages\\pandas\\core\\index.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   1690\u001b[0m                 raise ValueError('tolerance argument only valid if using pad, '\n\u001b[0;32m   1691\u001b[0m                                  'backfill or nearest lookups')\n\u001b[1;32m-> 1692\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m         indexer = self.get_indexer([key], method=method,\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:3979)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:3843)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12265)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12216)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'name_freq_pred'"
     ]
    }
   ],
   "source": [
    "#Prediction according to the frequency and the name (first word in the mail)\n",
    "\n",
    "\n",
    "with open(path_to_results + 'predictions_name_freq_.txt', 'wb') as my_file:\n",
    "    my_file.write(bytes('mid,recipients' + '\\n', 'UTF-8'))\n",
    "    for row in range(test_df.shape[0]):\n",
    "        mid = test_df['mid'][row]\n",
    "        name_freq_preds = test_df['name_freq_pred'][row]\n",
    "        my_file.write(bytes(str(mid) + ',' + ' '.join(name_freq_preds) + '\\n', 'UTF-8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ENSAE)",
   "language": "python",
   "name": "python_3_ensae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
